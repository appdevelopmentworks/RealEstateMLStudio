"""
é«˜åº¦åˆ†æãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« - SHAPåˆ†æã€äºˆæ¸¬ä¿¡é ¼åŒºé–“ã€PDFãƒ¬ãƒãƒ¼ãƒˆã€What-ifåˆ†æ
"""
import numpy as np
import pandas as pd
import shap
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.model_selection import cross_val_predict
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import io
import base64
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')


class SHAPAnalyzer:
    """SHAPåˆ†æã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, model, X_train: pd.DataFrame):
        """
        Parameters:
        -----------
        model : å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«
        X_train : å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ï¼ˆSHAPè¨ˆç®—ç”¨ï¼‰
        """
        self.model = model
        self.X_train = X_train
        self.explainer = None
        self.shap_values = None
        
    def calculate_shap_values(self, X: pd.DataFrame = None, max_samples: int = 500):
        """SHAPå€¤ã‚’è¨ˆç®—"""
        if X is None:
            X = self.X_train
        
        # ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒå¤šã„å ´åˆã¯åˆ¶é™
        if len(X) > max_samples:
            X_sample = X.sample(n=max_samples, random_state=42)
        else:
            X_sample = X.copy()
        
        # ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã‚’åˆ¤å®šã—ã¦é©åˆ‡ãªExplainerã‚’ä½¿ç”¨
        model_type = type(self.model).__name__
        
        try:
            if 'XGB' in model_type or 'LGBM' in model_type or 'LightGBM' in model_type:
                # XGBoost/LightGBMã¯TreeExplainerã‚’ä½¿ç”¨
                self.explainer = shap.TreeExplainer(self.model)
                self.shap_values = self.explainer.shap_values(X_sample)
            elif 'CatBoost' in model_type:
                # CatBoostã¯TreeExplainerã‚’ä½¿ç”¨
                self.explainer = shap.TreeExplainer(self.model)
                self.shap_values = self.explainer.shap_values(X_sample)
            elif 'Stacking' in model_type:
                # ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã¯KernelExplainerã‚’ä½¿ç”¨
                X_background = shap.sample(X_sample, min(100, len(X_sample)))
                self.explainer = shap.KernelExplainer(self.model.predict, X_background)
                self.shap_values = self.explainer.shap_values(X_sample.iloc[:min(100, len(X_sample))])
                X_sample = X_sample.iloc[:min(100, len(X_sample))]
            else:
                # ãã®ä»–ã®ãƒ¢ãƒ‡ãƒ«ã¯KernelExplainerã‚’ä½¿ç”¨
                X_background = shap.sample(X_sample, min(100, len(X_sample)))
                self.explainer = shap.KernelExplainer(self.model.predict, X_background)
                self.shap_values = self.explainer.shap_values(X_sample.iloc[:min(100, len(X_sample))])
                X_sample = X_sample.iloc[:min(100, len(X_sample))]
        except Exception as e:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: Permutation Explainerã‚’ä½¿ç”¨
            try:
                X_background = X_sample.iloc[:min(50, len(X_sample))]
                self.explainer = shap.Explainer(self.model.predict, X_background)
                shap_result = self.explainer(X_sample.iloc[:min(200, len(X_sample))])
                self.shap_values = shap_result.values
                X_sample = X_sample.iloc[:min(200, len(X_sample))]
            except Exception as e2:
                raise ValueError(f"SHAPå€¤ã®è¨ˆç®—ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e2)}")
        
        self.X_sample = X_sample
        return self.shap_values
    
    def get_feature_importance(self) -> pd.Series:
        """SHAPå€¤ãƒ™ãƒ¼ã‚¹ã®ç‰¹å¾´é‡é‡è¦åº¦ã‚’å–å¾—"""
        if self.shap_values is None:
            self.calculate_shap_values()
        
        importance = np.abs(self.shap_values).mean(axis=0)
        return pd.Series(importance, index=self.X_sample.columns).sort_values(ascending=False)
    
    def explain_prediction(self, X_single: pd.DataFrame) -> dict:
        """å˜ä¸€äºˆæ¸¬ã®èª¬æ˜ã‚’ç”Ÿæˆ"""
        if self.explainer is None:
            self.calculate_shap_values()
        
        # å˜ä¸€ã‚µãƒ³ãƒ—ãƒ«ã®SHAPå€¤ã‚’è¨ˆç®—
        model_type = type(self.model).__name__
        
        try:
            if hasattr(self.explainer, 'shap_values'):
                shap_values_single = self.explainer.shap_values(X_single)
            else:
                shap_result = self.explainer(X_single)
                shap_values_single = shap_result.values
        except Exception:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            X_background = self.X_sample.iloc[:min(50, len(self.X_sample))]
            temp_explainer = shap.Explainer(self.model.predict, X_background)
            shap_result = temp_explainer(X_single)
            shap_values_single = shap_result.values
        
        if len(shap_values_single.shape) > 1:
            shap_values_single = shap_values_single[0]
        
        # åŸºæº–å€¤ï¼ˆæœŸå¾…å€¤ï¼‰
        if hasattr(self.explainer, 'expected_value'):
            base_value = self.explainer.expected_value
            if isinstance(base_value, np.ndarray):
                base_value = base_value[0] if len(base_value) > 0 else float(base_value)
            base_value = float(base_value)
        else:
            base_value = float(self.model.predict(self.X_train).mean())
        
        # å„ç‰¹å¾´é‡ã®è²¢çŒ®åº¦ã‚’DataFrameã«
        contributions = pd.DataFrame({
            'ç‰¹å¾´é‡': X_single.columns,
            'å€¤': X_single.values[0],
            'SHAPå€¤': shap_values_single,
            'å½±éŸ¿': ['â†‘ ä¾¡æ ¼ä¸Šæ˜‡' if v > 0 else 'â†“ ä¾¡æ ¼ä¸‹è½' for v in shap_values_single]
        }).sort_values('SHAPå€¤', key=abs, ascending=False)
        
        prediction = base_value + shap_values_single.sum()
        
        return {
            'base_value': base_value,
            'shap_values': shap_values_single,
            'contributions': contributions,
            'prediction': prediction
        }
    
    def plot_summary(self, top_n: int = 15) -> go.Figure:
        """SHAP Summary Plotï¼ˆæ£’ã‚°ãƒ©ãƒ•ç‰ˆï¼‰"""
        if self.shap_values is None:
            self.calculate_shap_values()
        
        importance = self.get_feature_importance().head(top_n)
        
        fig = go.Figure(go.Bar(
            x=importance.values[::-1],
            y=importance.index[::-1],
            orientation='h',
            marker=dict(
                color=importance.values[::-1],
                colorscale='RdBu_r',
                colorbar=dict(title="é‡è¦åº¦")
            ),
            text=[f"{v:.4f}" for v in importance.values[::-1]],
            textposition='outside'
        ))
        
        fig.update_layout(
            title=dict(text="<b>SHAPç‰¹å¾´é‡é‡è¦åº¦</b>", font=dict(size=20)),
            xaxis_title="å¹³å‡ |SHAPå€¤|",
            yaxis_title="ç‰¹å¾´é‡",
            template='plotly_white',
            height=max(400, top_n * 30),
            margin=dict(l=150)
        )
        
        return fig
    
    def plot_waterfall(self, explanation: dict, feature_names: list = None) -> go.Figure:
        """ã‚¦ã‚©ãƒ¼ã‚¿ãƒ¼ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒ£ãƒ¼ãƒˆï¼ˆäºˆæ¸¬ã®å†…è¨³ï¼‰"""
        contributions = explanation['contributions']
        base_value = explanation['base_value']
        
        # ä¸Šä½ã®è²¢çŒ®è¦å› ã‚’è¡¨ç¤º
        top_positive = contributions[contributions['SHAPå€¤'] > 0].head(5)
        top_negative = contributions[contributions['SHAPå€¤'] < 0].head(5)
        display_df = pd.concat([top_positive, top_negative]).sort_values('SHAPå€¤', ascending=False)
        
        fig = go.Figure()
        
        cumsum = base_value
        y_positions = []
        colors = []
        texts = []
        
        # åŸºæº–å€¤
        y_positions.append("åŸºæº–å€¤")
        colors.append('#808080')
        texts.append(f"{base_value:.2f}")
        
        for _, row in display_df.iterrows():
            feature_label = f"{row['ç‰¹å¾´é‡']}={row['å€¤']:.2f}" if isinstance(row['å€¤'], float) else f"{row['ç‰¹å¾´é‡']}={row['å€¤']}"
            y_positions.append(feature_label)
            colors.append('#2ca02c' if row['SHAPå€¤'] > 0 else '#d62728')
            texts.append(f"{'+' if row['SHAPå€¤'] > 0 else ''}{row['SHAPå€¤']:.2f}")
        
        # æœ€çµ‚äºˆæ¸¬å€¤
        y_positions.append("äºˆæ¸¬å€¤")
        colors.append('#1f77b4')
        texts.append(f"{explanation['prediction']:.2f}")
        
        # å€¤ã‚’è¨ˆç®—
        values = [base_value]
        for _, row in display_df.iterrows():
            values.append(row['SHAPå€¤'])
        values.append(explanation['prediction'])
        
        fig = go.Figure(go.Waterfall(
            orientation="h",
            y=y_positions,
            x=values,
            connector={"line": {"color": "rgb(63, 63, 63)"}},
            decreasing={"marker": {"color": "#d62728"}},
            increasing={"marker": {"color": "#2ca02c"}},
            totals={"marker": {"color": "#1f77b4"}},
            text=texts,
            textposition="outside"
        ))
        
        fig.update_layout(
            title=dict(text="<b>äºˆæ¸¬å€¤ã®å†…è¨³ï¼ˆSHAP Waterfallï¼‰</b>", font=dict(size=18)),
            template='plotly_white',
            height=400 + len(display_df) * 30,
            showlegend=False
        )
        
        return fig
    
    def plot_force_single(self, explanation: dict) -> go.Figure:
        """Force Ploté¢¨ã®æ°´å¹³ãƒãƒ¼ãƒãƒ£ãƒ¼ãƒˆ"""
        contributions = explanation['contributions']
        base_value = explanation['base_value']
        prediction = explanation['prediction']
        
        # æ­£è² ã§åˆ†ã‘ã¦ã‚½ãƒ¼ãƒˆ
        positive = contributions[contributions['SHAPå€¤'] > 0].sort_values('SHAPå€¤', ascending=False)
        negative = contributions[contributions['SHAPå€¤'] < 0].sort_values('SHAPå€¤', ascending=True)
        
        fig = make_subplots(
            rows=2, cols=1,
            subplot_titles=("ä¾¡æ ¼ã‚’ä¸Šã’ã¦ã„ã‚‹è¦å›  â†‘", "ä¾¡æ ¼ã‚’ä¸‹ã’ã¦ã„ã‚‹è¦å›  â†“"),
            vertical_spacing=0.15
        )
        
        # æ­£ã®è¦å› 
        if len(positive) > 0:
            top_pos = positive.head(7)
            labels = [f"{row['ç‰¹å¾´é‡']}={row['å€¤']}" if not isinstance(row['å€¤'], str) else f"{row['ç‰¹å¾´é‡']}={row['å€¤']}" 
                     for _, row in top_pos.iterrows()]
            fig.add_trace(go.Bar(
                x=top_pos['SHAPå€¤'].values,
                y=labels,
                orientation='h',
                marker_color='#2ca02c',
                text=[f"+{v:.1f}" for v in top_pos['SHAPå€¤'].values],
                textposition='outside',
                name='ä¾¡æ ¼ä¸Šæ˜‡è¦å› '
            ), row=1, col=1)
        
        # è² ã®è¦å› 
        if len(negative) > 0:
            top_neg = negative.head(7)
            labels = [f"{row['ç‰¹å¾´é‡']}={row['å€¤']}" if not isinstance(row['å€¤'], str) else f"{row['ç‰¹å¾´é‡']}={row['å€¤']}" 
                     for _, row in top_neg.iterrows()]
            fig.add_trace(go.Bar(
                x=top_neg['SHAPå€¤'].values,
                y=labels,
                orientation='h',
                marker_color='#d62728',
                text=[f"{v:.1f}" for v in top_neg['SHAPå€¤'].values],
                textposition='outside',
                name='ä¾¡æ ¼ä¸‹è½è¦å› '
            ), row=2, col=1)
        
        fig.update_layout(
            title=dict(
                text=f"<b>äºˆæ¸¬ä¾¡æ ¼: {prediction:.2f}</b>ï¼ˆåŸºæº–å€¤: {base_value:.2f}ï¼‰",
                font=dict(size=18)
            ),
            template='plotly_white',
            height=500,
            showlegend=False
        )
        
        return fig


class PredictionInterval:
    """äºˆæ¸¬ä¿¡é ¼åŒºé–“ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, model, X_train: pd.DataFrame, y_train: pd.Series):
        self.model = model
        self.X_train = X_train
        self.y_train = y_train
        self.residuals = None
        self.residual_std = None
        
    def fit(self):
        """æ®‹å·®åˆ†å¸ƒã‚’å­¦ç¿’"""
        # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã§ã®äºˆæ¸¬
        y_pred_train = self.model.predict(self.X_train)
        self.residuals = self.y_train.values - y_pred_train
        self.residual_std = np.std(self.residuals)
        
        # æ®‹å·®ã®åˆ†ä½ç‚¹ã‚’è¨ˆç®—
        self.residual_percentiles = {
            '50': (np.percentile(self.residuals, 25), np.percentile(self.residuals, 75)),
            '80': (np.percentile(self.residuals, 10), np.percentile(self.residuals, 90)),
            '95': (np.percentile(self.residuals, 2.5), np.percentile(self.residuals, 97.5)),
        }
        
        return self
    
    def predict_with_interval(self, X: pd.DataFrame, confidence: float = 0.95) -> dict:
        """ä¿¡é ¼åŒºé–“ä»˜ãäºˆæ¸¬"""
        if self.residual_std is None:
            self.fit()
        
        predictions = self.model.predict(X)
        
        # ä¿¡é ¼åŒºé–“ã®è¨ˆç®—ï¼ˆæ­£è¦åˆ†å¸ƒã‚’ä»®å®šï¼‰
        from scipy import stats
        z_score = stats.norm.ppf(1 - (1 - confidence) / 2)
        margin = z_score * self.residual_std
        
        lower = predictions - margin
        upper = predictions + margin
        
        return {
            'predictions': predictions,
            'lower': lower,
            'upper': upper,
            'confidence': confidence,
            'margin': margin
        }
    
    def predict_single_with_interval(self, X_single: pd.DataFrame, confidence_levels: list = [0.5, 0.8, 0.95]) -> dict:
        """å˜ä¸€äºˆæ¸¬ã®è¤‡æ•°ä¿¡é ¼åŒºé–“"""
        if self.residual_std is None:
            self.fit()
        
        prediction = self.model.predict(X_single)[0]
        
        from scipy import stats
        intervals = {}
        for conf in confidence_levels:
            z = stats.norm.ppf(1 - (1 - conf) / 2)
            margin = z * self.residual_std
            intervals[f'{int(conf*100)}%'] = {
                'lower': prediction - margin,
                'upper': prediction + margin,
                'margin': margin
            }
        
        return {
            'prediction': prediction,
            'intervals': intervals,
            'residual_std': self.residual_std
        }
    
    def plot_prediction_interval(self, result: dict) -> go.Figure:
        """ä¿¡é ¼åŒºé–“ã®å¯è¦–åŒ–ï¼ˆå˜ä¸€äºˆæ¸¬ç”¨ï¼‰"""
        prediction = result['prediction']
        intervals = result['intervals']
        
        fig = go.Figure()
        
        colors = {
            '50%': 'rgba(31, 119, 180, 0.8)',
            '80%': 'rgba(31, 119, 180, 0.5)',
            '95%': 'rgba(31, 119, 180, 0.3)'
        }
        
        # ä¿¡é ¼åŒºé–“ã‚’è¿½åŠ ï¼ˆåºƒã„é †ï¼‰
        for conf in ['95%', '80%', '50%']:
            if conf in intervals:
                interval = intervals[conf]
                fig.add_trace(go.Bar(
                    x=[interval['upper'] - interval['lower']],
                    y=[conf],
                    base=[interval['lower']],
                    orientation='h',
                    marker_color=colors.get(conf, 'rgba(31, 119, 180, 0.5)'),
                    name=f'{conf}ä¿¡é ¼åŒºé–“',
                    text=[f"{interval['lower']:.1f} ã€œ {interval['upper']:.1f}"],
                    textposition='inside',
                    hovertemplate=f"{conf}ä¿¡é ¼åŒºé–“<br>ä¸‹é™: {interval['lower']:.2f}<br>ä¸Šé™: {interval['upper']:.2f}<extra></extra>"
                ))
        
        # äºˆæ¸¬å€¤ã®ãƒãƒ¼ã‚«ãƒ¼
        fig.add_trace(go.Scatter(
            x=[prediction],
            y=['50%', '80%', '95%'],
            mode='markers',
            marker=dict(color='red', size=15, symbol='diamond'),
            name=f'äºˆæ¸¬å€¤: {prediction:.2f}'
        ))
        
        fig.update_layout(
            title=dict(text=f"<b>äºˆæ¸¬ä¿¡é ¼åŒºé–“</b>ï¼ˆäºˆæ¸¬å€¤: {prediction:.2f}ï¼‰", font=dict(size=18)),
            xaxis_title="äºˆæ¸¬ä¾¡æ ¼",
            yaxis_title="ä¿¡é ¼æ°´æº–",
            template='plotly_white',
            height=300,
            showlegend=True,
            legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1),
            barmode='overlay'
        )
        
        return fig


class WhatIfAnalyzer:
    """What-ifåˆ†æã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, model, feature_columns: list, X_original: pd.DataFrame):
        self.model = model
        self.feature_columns = feature_columns
        self.X_original = X_original
        
    def analyze_feature_impact(self, X_base: pd.DataFrame, feature: str, 
                               values: list = None, n_points: int = 20) -> pd.DataFrame:
        """ç‰¹å®šã®ç‰¹å¾´é‡ã‚’å¤‰åŒ–ã•ã›ãŸæ™‚ã®äºˆæ¸¬å¤‰åŒ–ã‚’åˆ†æ"""
        
        if values is None:
            # å…ƒã®ãƒ‡ãƒ¼ã‚¿ã®ç¯„å›²ã§å€¤ã‚’ç”Ÿæˆ
            if feature in self.X_original.columns:
                min_val = self.X_original[feature].min()
                max_val = self.X_original[feature].max()
                values = np.linspace(min_val, max_val, n_points)
            else:
                raise ValueError(f"Feature '{feature}' not found")
        
        results = []
        base_prediction = self.model.predict(X_base)[0]
        
        for val in values:
            X_modified = X_base.copy()
            X_modified[feature] = val
            new_prediction = self.model.predict(X_modified)[0]
            
            results.append({
                feature: val,
                'äºˆæ¸¬ä¾¡æ ¼': new_prediction,
                'å¤‰åŒ–é‡': new_prediction - base_prediction,
                'å¤‰åŒ–ç‡(%)': (new_prediction - base_prediction) / base_prediction * 100
            })
        
        return pd.DataFrame(results)
    
    def compare_scenarios(self, X_base: pd.DataFrame, scenarios: dict) -> pd.DataFrame:
        """è¤‡æ•°ã‚·ãƒŠãƒªã‚ªã®æ¯”è¼ƒ"""
        results = []
        base_prediction = self.model.predict(X_base)[0]
        
        # ãƒ™ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹
        results.append({
            'ã‚·ãƒŠãƒªã‚ª': 'ç¾çŠ¶ï¼ˆãƒ™ãƒ¼ã‚¹ï¼‰',
            'äºˆæ¸¬ä¾¡æ ¼': base_prediction,
            'å¤‰åŒ–é‡': 0,
            'å¤‰åŒ–ç‡(%)': 0
        })
        
        for scenario_name, changes in scenarios.items():
            X_modified = X_base.copy()
            for feature, value in changes.items():
                if feature in X_modified.columns:
                    X_modified[feature] = value
            
            new_prediction = self.model.predict(X_modified)[0]
            results.append({
                'ã‚·ãƒŠãƒªã‚ª': scenario_name,
                'äºˆæ¸¬ä¾¡æ ¼': new_prediction,
                'å¤‰åŒ–é‡': new_prediction - base_prediction,
                'å¤‰åŒ–ç‡(%)': (new_prediction - base_prediction) / base_prediction * 100
            })
        
        return pd.DataFrame(results)
    
    def plot_feature_sensitivity(self, sensitivity_df: pd.DataFrame, feature: str) -> go.Figure:
        """ç‰¹å¾´é‡æ„Ÿåº¦åˆ†æã®ãƒ—ãƒ­ãƒƒãƒˆ"""
        
        fig = make_subplots(
            rows=1, cols=2,
            subplot_titles=("äºˆæ¸¬ä¾¡æ ¼ã®å¤‰åŒ–", "å¤‰åŒ–ç‡ (%)"),
            horizontal_spacing=0.12
        )
        
        # äºˆæ¸¬ä¾¡æ ¼
        fig.add_trace(go.Scatter(
            x=sensitivity_df[feature],
            y=sensitivity_df['äºˆæ¸¬ä¾¡æ ¼'],
            mode='lines+markers',
            marker=dict(size=8, color='#1f77b4'),
            line=dict(width=2),
            name='äºˆæ¸¬ä¾¡æ ¼'
        ), row=1, col=1)
        
        # å¤‰åŒ–ç‡
        colors = ['#2ca02c' if v >= 0 else '#d62728' for v in sensitivity_df['å¤‰åŒ–ç‡(%)']]
        fig.add_trace(go.Bar(
            x=sensitivity_df[feature],
            y=sensitivity_df['å¤‰åŒ–ç‡(%)'],
            marker_color=colors,
            name='å¤‰åŒ–ç‡'
        ), row=1, col=2)
        
        fig.add_hline(y=0, line_dash="dash", line_color="gray", row=1, col=2)
        
        fig.update_layout(
            title=dict(text=f"<b>What-ifåˆ†æ: {feature}ã®å½±éŸ¿</b>", font=dict(size=18)),
            template='plotly_white',
            height=400,
            showlegend=False
        )
        
        fig.update_xaxes(title_text=feature, row=1, col=1)
        fig.update_xaxes(title_text=feature, row=1, col=2)
        fig.update_yaxes(title_text="äºˆæ¸¬ä¾¡æ ¼", row=1, col=1)
        fig.update_yaxes(title_text="å¤‰åŒ–ç‡ (%)", row=1, col=2)
        
        return fig
    
    def plot_scenario_comparison(self, scenario_df: pd.DataFrame) -> go.Figure:
        """ã‚·ãƒŠãƒªã‚ªæ¯”è¼ƒã®ãƒ—ãƒ­ãƒƒãƒˆ"""
        
        colors = ['#808080'] + ['#2ca02c' if v >= 0 else '#d62728' for v in scenario_df['å¤‰åŒ–é‡'].iloc[1:]]
        
        fig = go.Figure()
        
        fig.add_trace(go.Bar(
            x=scenario_df['ã‚·ãƒŠãƒªã‚ª'],
            y=scenario_df['äºˆæ¸¬ä¾¡æ ¼'],
            marker_color=colors,
            text=[f"{v:,.0f}<br>({scenario_df['å¤‰åŒ–ç‡(%)'].iloc[i]:+.1f}%)" 
                  for i, v in enumerate(scenario_df['äºˆæ¸¬ä¾¡æ ¼'])],
            textposition='outside'
        ))
        
        # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’è¿½åŠ 
        base_price = scenario_df['äºˆæ¸¬ä¾¡æ ¼'].iloc[0]
        fig.add_hline(y=base_price, line_dash="dash", line_color="gray",
                     annotation_text=f"ãƒ™ãƒ¼ã‚¹: {base_price:,.0f}")
        
        fig.update_layout(
            title=dict(text="<b>ã‚·ãƒŠãƒªã‚ªæ¯”è¼ƒåˆ†æ</b>", font=dict(size=18)),
            xaxis_title="ã‚·ãƒŠãƒªã‚ª",
            yaxis_title="äºˆæ¸¬ä¾¡æ ¼",
            template='plotly_white',
            height=450
        )
        
        return fig


class PDFReportGenerator:
    """PDFãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.report_data = {}
        
    def generate_report(self, 
                       prediction_result: dict,
                       shap_explanation: dict = None,
                       interval_result: dict = None,
                       model_metrics: dict = None,
                       input_data: pd.DataFrame = None,
                       target_column: str = "ä¾¡æ ¼") -> bytes:
        """PDFãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        from fpdf import FPDF
        
        class PDF(FPDF):
            def header(self):
                self.set_font('Helvetica', 'B', 16)
                self.cell(0, 10, 'RealEstateMLStudio', 0, 1, 'C')
                self.set_font('Helvetica', '', 10)
                self.cell(0, 5, 'Property Price Prediction Report', 0, 1, 'C')
                self.ln(5)
                self.line(10, self.get_y(), 200, self.get_y())
                self.ln(5)
                
            def footer(self):
                self.set_y(-15)
                self.set_font('Helvetica', 'I', 8)
                self.cell(0, 10, f'Page {self.page_no()}/{{nb}} | Generated: {datetime.now().strftime("%Y-%m-%d %H:%M")}', 0, 0, 'C')
        
        pdf = PDF()
        pdf.alias_nb_pages()
        pdf.add_page()
        pdf.set_auto_page_break(auto=True, margin=15)
        
        # 1. äºˆæ¸¬çµæœã‚µãƒãƒªãƒ¼
        pdf.set_font('Helvetica', 'B', 14)
        pdf.cell(0, 10, '1. Prediction Summary', 0, 1)
        pdf.set_font('Helvetica', '', 11)
        
        prediction = prediction_result.get('prediction', 0)
        pdf.set_font('Helvetica', 'B', 24)
        pdf.set_text_color(31, 119, 180)
        pdf.cell(0, 15, f'Predicted {target_column}: {prediction:,.2f}', 0, 1, 'C')
        pdf.set_text_color(0, 0, 0)
        
        # ä¿¡é ¼åŒºé–“
        if interval_result:
            pdf.set_font('Helvetica', '', 10)
            intervals = interval_result.get('intervals', {})
            if '95%' in intervals:
                lower = intervals['95%']['lower']
                upper = intervals['95%']['upper']
                pdf.cell(0, 8, f'95% Confidence Interval: {lower:,.2f} - {upper:,.2f}', 0, 1, 'C')
        
        pdf.ln(5)
        
        # 2. å…¥åŠ›ãƒ‡ãƒ¼ã‚¿
        if input_data is not None:
            pdf.set_font('Helvetica', 'B', 14)
            pdf.cell(0, 10, '2. Input Features', 0, 1)
            pdf.set_font('Helvetica', '', 9)
            
            col_width = 60
            row_height = 7
            
            for col in input_data.columns:
                value = input_data[col].iloc[0]
                if isinstance(value, float):
                    value_str = f"{value:.4f}"
                else:
                    value_str = str(value)
                pdf.cell(col_width, row_height, str(col)[:25], 1, 0)
                pdf.cell(col_width, row_height, value_str[:25], 1, 1)
            
            pdf.ln(5)
        
        # 3. SHAPåˆ†æçµæœ
        if shap_explanation:
            pdf.set_font('Helvetica', 'B', 14)
            pdf.cell(0, 10, '3. SHAP Analysis - Price Factors', 0, 1)
            pdf.set_font('Helvetica', '', 9)
            
            contributions = shap_explanation.get('contributions', pd.DataFrame())
            if not contributions.empty:
                # ä¸Šä½è¦å› 
                positive = contributions[contributions['SHAPå€¤'] > 0].head(5)
                negative = contributions[contributions['SHAPå€¤'] < 0].head(5)
                
                pdf.set_font('Helvetica', 'B', 10)
                pdf.set_text_color(44, 160, 44)
                pdf.cell(0, 8, 'Positive Factors (Increase Price):', 0, 1)
                pdf.set_text_color(0, 0, 0)
                pdf.set_font('Helvetica', '', 9)
                
                for _, row in positive.iterrows():
                    feature = str(row['ç‰¹å¾´é‡'])[:20]
                    value = row['å€¤']
                    shap_val = row['SHAPå€¤']
                    if isinstance(value, float):
                        pdf.cell(0, 6, f"  + {feature} = {value:.2f} (SHAP: +{shap_val:.2f})", 0, 1)
                    else:
                        pdf.cell(0, 6, f"  + {feature} = {value} (SHAP: +{shap_val:.2f})", 0, 1)
                
                pdf.ln(3)
                pdf.set_font('Helvetica', 'B', 10)
                pdf.set_text_color(214, 39, 40)
                pdf.cell(0, 8, 'Negative Factors (Decrease Price):', 0, 1)
                pdf.set_text_color(0, 0, 0)
                pdf.set_font('Helvetica', '', 9)
                
                for _, row in negative.iterrows():
                    feature = str(row['ç‰¹å¾´é‡'])[:20]
                    value = row['å€¤']
                    shap_val = row['SHAPå€¤']
                    if isinstance(value, float):
                        pdf.cell(0, 6, f"  - {feature} = {value:.2f} (SHAP: {shap_val:.2f})", 0, 1)
                    else:
                        pdf.cell(0, 6, f"  - {feature} = {value} (SHAP: {shap_val:.2f})", 0, 1)
            
            pdf.ln(5)
        
        # 4. ãƒ¢ãƒ‡ãƒ«æ€§èƒ½
        if model_metrics:
            pdf.set_font('Helvetica', 'B', 14)
            pdf.cell(0, 10, '4. Model Performance Metrics', 0, 1)
            pdf.set_font('Helvetica', '', 10)
            
            metrics_text = [
                f"R2 Score: {model_metrics.get('r2', 0):.4f}",
                f"RMSE: {model_metrics.get('rmse', 0):.4f}",
                f"MAE: {model_metrics.get('mae', 0):.4f}",
                f"MAPE: {model_metrics.get('mape', 0):.2f}%"
            ]
            
            for text in metrics_text:
                pdf.cell(0, 7, text, 0, 1)
        
        # 5. å…è²¬äº‹é …
        pdf.ln(10)
        pdf.set_font('Helvetica', 'I', 8)
        pdf.set_text_color(128, 128, 128)
        pdf.multi_cell(0, 4, 
            'Disclaimer: This prediction is generated by a machine learning model and should be used for reference only. '
            'Actual property prices may vary based on market conditions, property-specific factors, and other variables '
            'not captured in the model. Please consult with a qualified professional for important decisions.')
        
        # PDFã‚’ãƒã‚¤ãƒˆã¨ã—ã¦è¿”ã™
        return bytes(pdf.output())
    
    def get_download_link(self, pdf_bytes: bytes, filename: str = "prediction_report.pdf") -> str:
        """ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒªãƒ³ã‚¯ã‚’ç”Ÿæˆ"""
        b64 = base64.b64encode(pdf_bytes).decode()
        return f'<a href="data:application/pdf;base64,{b64}" download="{filename}">ğŸ“¥ PDFãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰</a>'


class SimilarPropertyFinder:
    """é¡ä¼¼ç‰©ä»¶æ¤œç´¢ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, df: pd.DataFrame, feature_columns: list, target_column: str):
        self.df = df.copy()
        self.feature_columns = feature_columns
        self.target_column = target_column
        self.scaler = None
        self.scaled_features = None
        
    def fit(self):
        """ç‰¹å¾´é‡ã‚’ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°"""
        from sklearn.preprocessing import StandardScaler
        
        # æ•°å€¤åˆ—ã®ã¿æŠ½å‡º
        numeric_cols = [col for col in self.feature_columns 
                       if col in self.df.columns and self.df[col].dtype in ['int64', 'float64', 'int32', 'float32']]
        
        self.numeric_cols = numeric_cols
        self.scaler = StandardScaler()
        self.scaled_features = self.scaler.fit_transform(self.df[numeric_cols].fillna(0))
        
        return self
    
    def find_similar(self, X_query: pd.DataFrame, n_neighbors: int = 5, 
                    method: str = 'euclidean') -> pd.DataFrame:
        """é¡ä¼¼ç‰©ä»¶ã‚’æ¤œç´¢"""
        if self.scaler is None:
            self.fit()
        
        from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances
        
        # ã‚¯ã‚¨ãƒªã‚’ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
        query_numeric = X_query[self.numeric_cols].fillna(0).values
        query_scaled = self.scaler.transform(query_numeric)
        
        # è·é›¢/é¡ä¼¼åº¦ã‚’è¨ˆç®—
        if method == 'cosine':
            similarities = cosine_similarity(query_scaled, self.scaled_features)[0]
            indices = np.argsort(similarities)[::-1][:n_neighbors]
            scores = similarities[indices]
        else:  # euclidean
            distances = euclidean_distances(query_scaled, self.scaled_features)[0]
            indices = np.argsort(distances)[:n_neighbors]
            scores = 1 / (1 + distances[indices])  # é¡ä¼¼åº¦ã«å¤‰æ›
        
        # çµæœã‚’ä½œæˆ
        similar_df = self.df.iloc[indices].copy()
        similar_df['é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢'] = scores
        similar_df['é †ä½'] = range(1, len(similar_df) + 1)
        
        # åˆ—ã®é †åºã‚’èª¿æ•´
        cols = ['é †ä½', 'é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢'] + [self.target_column] + \
               [c for c in similar_df.columns if c not in ['é †ä½', 'é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢', self.target_column]]
        
        return similar_df[cols]
    
    def plot_similar_properties(self, query_prediction: float, similar_df: pd.DataFrame) -> go.Figure:
        """é¡ä¼¼ç‰©ä»¶ã®æ¯”è¼ƒãƒ—ãƒ­ãƒƒãƒˆ"""
        fig = go.Figure()
        
        # é¡ä¼¼ç‰©ä»¶ã®å®Ÿç¸¾ä¾¡æ ¼
        fig.add_trace(go.Bar(
            x=[f"é¡ä¼¼ç‰©ä»¶{i+1}" for i in range(len(similar_df))],
            y=similar_df[self.target_column].values,
            name='å®Ÿç¸¾ä¾¡æ ¼',
            marker_color='#1f77b4',
            text=[f"{v:,.0f}<br>(é¡ä¼¼åº¦:{s:.2f})" 
                  for v, s in zip(similar_df[self.target_column].values, similar_df['é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢'].values)],
            textposition='outside'
        ))
        
        # äºˆæ¸¬ä¾¡æ ¼ã®ãƒ©ã‚¤ãƒ³
        fig.add_hline(y=query_prediction, line_dash="dash", line_color="red",
                     annotation_text=f"äºˆæ¸¬ä¾¡æ ¼: {query_prediction:,.0f}")
        
        # å¹³å‡ä¾¡æ ¼ã®ãƒ©ã‚¤ãƒ³
        avg_price = similar_df[self.target_column].mean()
        fig.add_hline(y=avg_price, line_dash="dot", line_color="green",
                     annotation_text=f"é¡ä¼¼ç‰©ä»¶å¹³å‡: {avg_price:,.0f}")
        
        fig.update_layout(
            title=dict(text="<b>é¡ä¼¼ç‰©ä»¶ã¨ã®ä¾¡æ ¼æ¯”è¼ƒ</b>", font=dict(size=18)),
            xaxis_title="ç‰©ä»¶",
            yaxis_title=self.target_column,
            template='plotly_white',
            height=450
        )
        
        return fig


class DataQualityChecker:
    """ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, df: pd.DataFrame):
        self.df = df.copy()
        self.report = {}
        
    def check_all(self) -> dict:
        """å…¨ã¦ã®ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œ"""
        self.report = {
            'duplicates': self._check_duplicates(),
            'missing': self._check_missing(),
            'outliers': self._check_outliers(),
            'type_issues': self._check_type_issues(),
            'value_ranges': self._check_value_ranges(),
            'correlations': self._check_high_correlations(),
            'summary': {}
        }
        
        # ã‚µãƒãƒªãƒ¼ã‚’ä½œæˆ
        total_issues = (
            self.report['duplicates']['count'] +
            len(self.report['missing']['columns_with_missing']) +
            sum(len(v) for v in self.report['outliers'].values()) +
            len(self.report['type_issues'])
        )
        
        self.report['summary'] = {
            'total_rows': len(self.df),
            'total_columns': len(self.df.columns),
            'total_issues': total_issues,
            'quality_score': max(0, 100 - total_issues * 2)  # ç°¡æ˜“ã‚¹ã‚³ã‚¢
        }
        
        return self.report
    
    def _check_duplicates(self) -> dict:
        """é‡è¤‡è¡Œãƒã‚§ãƒƒã‚¯"""
        duplicates = self.df.duplicated()
        duplicate_rows = self.df[duplicates]
        
        return {
            'count': duplicates.sum(),
            'percentage': (duplicates.sum() / len(self.df) * 100),
            'indices': duplicate_rows.index.tolist()[:10]  # æœ€åˆã®10ä»¶
        }
    
    def _check_missing(self) -> dict:
        """æ¬ æå€¤ãƒã‚§ãƒƒã‚¯"""
        missing = self.df.isnull().sum()
        missing_pct = (missing / len(self.df) * 100).round(2)
        
        columns_with_missing = missing[missing > 0].to_dict()
        
        return {
            'total_missing_cells': self.df.isnull().sum().sum(),
            'columns_with_missing': columns_with_missing,
            'missing_percentage': missing_pct[missing_pct > 0].to_dict()
        }
    
    def _check_outliers(self) -> dict:
        """ç•°å¸¸å€¤ãƒã‚§ãƒƒã‚¯ï¼ˆIQRæ³•ï¼‰"""
        outliers = {}
        
        numeric_cols = self.df.select_dtypes(include=[np.number]).columns
        
        for col in numeric_cols:
            Q1 = self.df[col].quantile(0.25)
            Q3 = self.df[col].quantile(0.75)
            IQR = Q3 - Q1
            
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            
            outlier_mask = (self.df[col] < lower_bound) | (self.df[col] > upper_bound)
            outlier_count = outlier_mask.sum()
            
            if outlier_count > 0:
                outlier_values = self.df.loc[outlier_mask, col].head(5).tolist()
                outliers[col] = {
                    'count': int(outlier_count),
                    'percentage': round(outlier_count / len(self.df) * 100, 2),
                    'lower_bound': round(lower_bound, 2),
                    'upper_bound': round(upper_bound, 2),
                    'sample_values': outlier_values
                }
        
        return outliers
    
    def _check_type_issues(self) -> list:
        """ãƒ‡ãƒ¼ã‚¿å‹ã®å•é¡Œã‚’ãƒã‚§ãƒƒã‚¯"""
        issues = []
        
        for col in self.df.columns:
            # æ•°å€¤åˆ—ã«æ–‡å­—åˆ—ãŒæ··å…¥ã—ã¦ã„ãªã„ã‹ãƒã‚§ãƒƒã‚¯
            if self.df[col].dtype == 'object':
                # æ•°å€¤ã«å¤‰æ›å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯
                numeric_convertible = pd.to_numeric(self.df[col], errors='coerce')
                non_numeric_count = numeric_convertible.isna().sum() - self.df[col].isna().sum()
                
                if non_numeric_count > 0 and non_numeric_count < len(self.df) * 0.5:
                    issues.append({
                        'column': col,
                        'issue': 'æ•°å€¤ã¨æ–‡å­—åˆ—ãŒæ··åœ¨',
                        'non_numeric_count': int(non_numeric_count)
                    })
        
        return issues
    
    def _check_value_ranges(self) -> dict:
        """å€¤ã®ç¯„å›²ãƒã‚§ãƒƒã‚¯ï¼ˆè² ã®å€¤ãªã©ï¼‰"""
        issues = {}
        
        numeric_cols = self.df.select_dtypes(include=[np.number]).columns
        
        for col in numeric_cols:
            col_issues = []
            
            # è² ã®å€¤ãƒã‚§ãƒƒã‚¯
            negative_count = (self.df[col] < 0).sum()
            if negative_count > 0:
                col_issues.append(f"è² ã®å€¤: {negative_count}ä»¶")
            
            # ã‚¼ãƒ­å€¤ãƒã‚§ãƒƒã‚¯
            zero_count = (self.df[col] == 0).sum()
            if zero_count > len(self.df) * 0.5:  # 50%ä»¥ä¸ŠãŒã‚¼ãƒ­
                col_issues.append(f"ã‚¼ãƒ­å€¤ãŒå¤šã„: {zero_count}ä»¶ ({zero_count/len(self.df)*100:.1f}%)")
            
            if col_issues:
                issues[col] = col_issues
        
        return issues
    
    def _check_high_correlations(self, threshold: float = 0.95) -> list:
        """é«˜ã„ç›¸é–¢ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆå¤šé‡å…±ç·šæ€§ï¼‰"""
        numeric_df = self.df.select_dtypes(include=[np.number])
        
        if len(numeric_df.columns) < 2:
            return []
        
        corr_matrix = numeric_df.corr().abs()
        
        # ä¸Šä¸‰è§’è¡Œåˆ—ã‹ã‚‰é«˜ã„ç›¸é–¢ã‚’æŠ½å‡º
        high_corr = []
        for i in range(len(corr_matrix.columns)):
            for j in range(i + 1, len(corr_matrix.columns)):
                if corr_matrix.iloc[i, j] >= threshold:
                    high_corr.append({
                        'feature1': corr_matrix.columns[i],
                        'feature2': corr_matrix.columns[j],
                        'correlation': round(corr_matrix.iloc[i, j], 4)
                    })
        
        return high_corr
    
    def get_summary_dataframe(self) -> pd.DataFrame:
        """ã‚µãƒãƒªãƒ¼ã‚’DataFrameã§å–å¾—"""
        if not self.report:
            self.check_all()
        
        data = [
            {'ãƒã‚§ãƒƒã‚¯é …ç›®': 'ç·è¡Œæ•°', 'çµæœ': self.report['summary']['total_rows'], 'çŠ¶æ…‹': 'âœ…'},
            {'ãƒã‚§ãƒƒã‚¯é …ç›®': 'ç·åˆ—æ•°', 'çµæœ': self.report['summary']['total_columns'], 'çŠ¶æ…‹': 'âœ…'},
            {'ãƒã‚§ãƒƒã‚¯é …ç›®': 'é‡è¤‡è¡Œ', 'çµæœ': self.report['duplicates']['count'], 
             'çŠ¶æ…‹': 'âœ…' if self.report['duplicates']['count'] == 0 else 'âš ï¸'},
            {'ãƒã‚§ãƒƒã‚¯é …ç›®': 'æ¬ æå€¤ã®ã‚ã‚‹åˆ—', 'çµæœ': len(self.report['missing']['columns_with_missing']),
             'çŠ¶æ…‹': 'âœ…' if len(self.report['missing']['columns_with_missing']) == 0 else 'âš ï¸'},
            {'ãƒã‚§ãƒƒã‚¯é …ç›®': 'ç•°å¸¸å€¤ã®ã‚ã‚‹åˆ—', 'çµæœ': len(self.report['outliers']),
             'çŠ¶æ…‹': 'âœ…' if len(self.report['outliers']) == 0 else 'âš ï¸'},
            {'ãƒã‚§ãƒƒã‚¯é …ç›®': 'å‹ã®å•é¡Œ', 'çµæœ': len(self.report['type_issues']),
             'çŠ¶æ…‹': 'âœ…' if len(self.report['type_issues']) == 0 else 'âš ï¸'},
            {'ãƒã‚§ãƒƒã‚¯é …ç›®': 'é«˜ç›¸é–¢ãƒšã‚¢', 'çµæœ': len(self.report['correlations']),
             'çŠ¶æ…‹': 'âœ…' if len(self.report['correlations']) == 0 else 'âš ï¸'},
            {'ãƒã‚§ãƒƒã‚¯é …ç›®': 'å“è³ªã‚¹ã‚³ã‚¢', 'çµæœ': f"{self.report['summary']['quality_score']}/100",
             'çŠ¶æ…‹': 'âœ…' if self.report['summary']['quality_score'] >= 80 else 'âš ï¸'}
        ]
        
        return pd.DataFrame(data)
    
    def plot_quality_overview(self) -> go.Figure:
        """å“è³ªæ¦‚è¦ã®ãƒ—ãƒ­ãƒƒãƒˆ"""
        if not self.report:
            self.check_all()
        
        # ã‚²ãƒ¼ã‚¸ãƒãƒ£ãƒ¼ãƒˆ
        fig = go.Figure(go.Indicator(
            mode="gauge+number",
            value=self.report['summary']['quality_score'],
            domain={'x': [0, 1], 'y': [0, 1]},
            title={'text': "ãƒ‡ãƒ¼ã‚¿å“è³ªã‚¹ã‚³ã‚¢", 'font': {'size': 24}},
            gauge={
                'axis': {'range': [0, 100], 'tickwidth': 1},
                'bar': {'color': "darkblue"},
                'bgcolor': "white",
                'borderwidth': 2,
                'bordercolor': "gray",
                'steps': [
                    {'range': [0, 50], 'color': '#ff6b6b'},
                    {'range': [50, 80], 'color': '#ffd93d'},
                    {'range': [80, 100], 'color': '#6bcb77'}
                ],
                'threshold': {
                    'line': {'color': "red", 'width': 4},
                    'thickness': 0.75,
                    'value': 80
                }
            }
        ))
        
        fig.update_layout(
            height=300,
            template='plotly_white'
        )
        
        return fig


class FeatureEngineer:
    """ç‰¹å¾´é‡è‡ªå‹•ç”Ÿæˆã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, df: pd.DataFrame, target_column: str):
        self.df = df.copy()
        self.target_column = target_column
        self.new_features = []
        self.feature_info = []
        
    def generate_all(self, include_interactions: bool = True,
                    include_polynomial: bool = True,
                    include_ratios: bool = True,
                    include_binning: bool = True) -> pd.DataFrame:
        """å…¨ã¦ã®ç‰¹å¾´é‡ã‚’ç”Ÿæˆ"""
        
        df_new = self.df.copy()
        numeric_cols = df_new.select_dtypes(include=[np.number]).columns.tolist()
        
        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ—ã‚’é™¤å¤–
        if self.target_column in numeric_cols:
            numeric_cols.remove(self.target_column)
        
        if include_interactions:
            df_new = self._create_interactions(df_new, numeric_cols[:5])  # ä¸Šä½5åˆ—
        
        if include_polynomial:
            df_new = self._create_polynomial(df_new, numeric_cols[:5])
        
        if include_ratios:
            df_new = self._create_ratios(df_new, numeric_cols[:5])
        
        if include_binning:
            df_new = self._create_binning(df_new, numeric_cols)
        
        return df_new
    
    def _create_interactions(self, df: pd.DataFrame, columns: list) -> pd.DataFrame:
        """äº¤äº’ä½œç”¨é …ã‚’ä½œæˆ"""
        for i, col1 in enumerate(columns):
            for col2 in columns[i+1:]:
                new_col = f"{col1}_Ã—_{col2}"
                df[new_col] = df[col1] * df[col2]
                self.new_features.append(new_col)
                self.feature_info.append({
                    'ç‰¹å¾´é‡': new_col,
                    'ã‚¿ã‚¤ãƒ—': 'äº¤äº’ä½œç”¨',
                    'å…ƒã®ç‰¹å¾´é‡': f"{col1}, {col2}",
                    'èª¬æ˜': f"{col1}ã¨{col2}ã®ç©"
                })
        
        return df
    
    def _create_polynomial(self, df: pd.DataFrame, columns: list) -> pd.DataFrame:
        """å¤šé …å¼ç‰¹å¾´é‡ã‚’ä½œæˆ"""
        for col in columns:
            # 2ä¹—
            new_col = f"{col}_squared"
            df[new_col] = df[col] ** 2
            self.new_features.append(new_col)
            self.feature_info.append({
                'ç‰¹å¾´é‡': new_col,
                'ã‚¿ã‚¤ãƒ—': 'å¤šé …å¼',
                'å…ƒã®ç‰¹å¾´é‡': col,
                'èª¬æ˜': f"{col}ã®2ä¹—"
            })
            
            # å¹³æ–¹æ ¹ï¼ˆæ­£ã®å€¤ã®ã¿ï¼‰
            if (df[col] >= 0).all():
                new_col = f"{col}_sqrt"
                df[new_col] = np.sqrt(df[col])
                self.new_features.append(new_col)
                self.feature_info.append({
                    'ç‰¹å¾´é‡': new_col,
                    'ã‚¿ã‚¤ãƒ—': 'å¤šé …å¼',
                    'å…ƒã®ç‰¹å¾´é‡': col,
                    'èª¬æ˜': f"{col}ã®å¹³æ–¹æ ¹"
                })
        
        return df
    
    def _create_ratios(self, df: pd.DataFrame, columns: list) -> pd.DataFrame:
        """æ¯”ç‡ç‰¹å¾´é‡ã‚’ä½œæˆ"""
        for i, col1 in enumerate(columns):
            for col2 in columns[i+1:]:
                # ã‚¼ãƒ­é™¤ç®—ã‚’é¿ã‘ã‚‹
                if (df[col2] != 0).all():
                    new_col = f"{col1}_per_{col2}"
                    df[new_col] = df[col1] / df[col2]
                    self.new_features.append(new_col)
                    self.feature_info.append({
                        'ç‰¹å¾´é‡': new_col,
                        'ã‚¿ã‚¤ãƒ—': 'æ¯”ç‡',
                        'å…ƒã®ç‰¹å¾´é‡': f"{col1}, {col2}",
                        'èª¬æ˜': f"{col1}Ã·{col2}"
                    })
        
        return df
    
    def _create_binning(self, df: pd.DataFrame, columns: list, n_bins: int = 5) -> pd.DataFrame:
        """ãƒ“ãƒ‹ãƒ³ã‚°ç‰¹å¾´é‡ã‚’ä½œæˆ"""
        for col in columns[:3]:  # ä¸Šä½3åˆ—ã®ã¿
            new_col = f"{col}_bin"
            try:
                df[new_col] = pd.qcut(df[col], q=n_bins, labels=False, duplicates='drop')
                self.new_features.append(new_col)
                self.feature_info.append({
                    'ç‰¹å¾´é‡': new_col,
                    'ã‚¿ã‚¤ãƒ—': 'ãƒ“ãƒ‹ãƒ³ã‚°',
                    'å…ƒã®ç‰¹å¾´é‡': col,
                    'èª¬æ˜': f"{col}ã‚’{n_bins}åˆ†ä½ã«åˆ†å‰²"
                })
            except Exception:
                pass  # ãƒ“ãƒ‹ãƒ³ã‚°ã§ããªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
        
        return df
    
    def get_feature_info(self) -> pd.DataFrame:
        """ç”Ÿæˆã—ãŸç‰¹å¾´é‡ã®æƒ…å ±ã‚’å–å¾—"""
        return pd.DataFrame(self.feature_info)
    
    def evaluate_features(self, model, X_train, y_train, X_test, y_test) -> pd.DataFrame:
        """ç‰¹å¾´é‡ã®æœ‰åŠ¹æ€§ã‚’è©•ä¾¡"""
        from sklearn.metrics import r2_score
        
        results = []
        
        # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³
        model.fit(X_train, y_train)
        base_score = r2_score(y_test, model.predict(X_test))
        
        # å„æ–°ç‰¹å¾´é‡ã‚’è¿½åŠ ã—ã¦è©•ä¾¡
        for feat in self.new_features:
            if feat in X_train.columns:
                continue
                
            # æ–°ç‰¹å¾´é‡ã‚’è¿½åŠ 
            X_train_new = X_train.copy()
            X_test_new = X_test.copy()
            
            # ç‰¹å¾´é‡ã‚’è¿½åŠ 
            # ... (å®Ÿéš›ã®å®Ÿè£…ã§ã¯å…ƒãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç‰¹å¾´é‡ã‚’å†è¨ˆç®—)
            
        return pd.DataFrame(results)


class PredictionHistory:
    """äºˆæ¸¬å±¥æ­´ç®¡ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.history = []
        
    def add_prediction(self, input_data: dict, prediction: float, 
                      confidence_interval: dict = None,
                      model_type: str = None,
                      similar_properties: pd.DataFrame = None):
        """äºˆæ¸¬ã‚’å±¥æ­´ã«è¿½åŠ """
        record = {
            'id': len(self.history) + 1,
            'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'input_data': input_data,
            'prediction': prediction,
            'confidence_interval': confidence_interval,
            'model_type': model_type,
            'similar_avg': similar_properties[similar_properties.columns[2]].mean() if similar_properties is not None else None
        }
        
        self.history.append(record)
        return record
    
    def get_history_dataframe(self) -> pd.DataFrame:
        """å±¥æ­´ã‚’DataFrameã§å–å¾—"""
        if not self.history:
            return pd.DataFrame()
        
        records = []
        for h in self.history:
            record = {
                'ID': h['id'],
                'æ—¥æ™‚': h['timestamp'],
                'äºˆæ¸¬ä¾¡æ ¼': h['prediction'],
                'ãƒ¢ãƒ‡ãƒ«': h['model_type'] or '-',
            }
            
            # ä¿¡é ¼åŒºé–“
            if h['confidence_interval']:
                intervals = h['confidence_interval'].get('intervals', {})
                if '95%' in intervals:
                    record['95%ä¸‹é™'] = intervals['95%']['lower']
                    record['95%ä¸Šé™'] = intervals['95%']['upper']
            
            # é¡ä¼¼ç‰©ä»¶å¹³å‡
            if h['similar_avg']:
                record['é¡ä¼¼ç‰©ä»¶å¹³å‡'] = h['similar_avg']
            
            # å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®ã‚µãƒãƒªãƒ¼
            input_summary = ', '.join([f"{k}={v}" for k, v in list(h['input_data'].items())[:3]])
            record['å…¥åŠ›æ¡ä»¶'] = input_summary + '...' if len(h['input_data']) > 3 else input_summary
            
            records.append(record)
        
        return pd.DataFrame(records)
    
    def clear_history(self):
        """å±¥æ­´ã‚’ã‚¯ãƒªã‚¢"""
        self.history = []
    
    def export_to_csv(self) -> str:
        """CSVã¨ã—ã¦ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        df = self.get_history_dataframe()
        return df.to_csv(index=False)
    
    def export_to_json(self) -> str:
        """JSONã¨ã—ã¦ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        import json
        return json.dumps(self.history, ensure_ascii=False, indent=2, default=str)
    
    def plot_history(self) -> go.Figure:
        """äºˆæ¸¬å±¥æ­´ã®ãƒ—ãƒ­ãƒƒãƒˆ"""
        if not self.history:
            return None
        
        df = self.get_history_dataframe()
        
        fig = go.Figure()
        
        # äºˆæ¸¬ä¾¡æ ¼
        fig.add_trace(go.Scatter(
            x=df['æ—¥æ™‚'],
            y=df['äºˆæ¸¬ä¾¡æ ¼'],
            mode='lines+markers',
            name='äºˆæ¸¬ä¾¡æ ¼',
            marker=dict(size=10, color='#1f77b4'),
            line=dict(width=2)
        ))
        
        # ä¿¡é ¼åŒºé–“ãŒã‚ã‚Œã°è¿½åŠ 
        if '95%ä¸‹é™' in df.columns and '95%ä¸Šé™' in df.columns:
            fig.add_trace(go.Scatter(
                x=df['æ—¥æ™‚'].tolist() + df['æ—¥æ™‚'].tolist()[::-1],
                y=df['95%ä¸Šé™'].tolist() + df['95%ä¸‹é™'].tolist()[::-1],
                fill='toself',
                fillcolor='rgba(31, 119, 180, 0.2)',
                line=dict(color='rgba(255,255,255,0)'),
                name='95%ä¿¡é ¼åŒºé–“'
            ))
        
        # é¡ä¼¼ç‰©ä»¶å¹³å‡ãŒã‚ã‚Œã°è¿½åŠ 
        if 'é¡ä¼¼ç‰©ä»¶å¹³å‡' in df.columns:
            fig.add_trace(go.Scatter(
                x=df['æ—¥æ™‚'],
                y=df['é¡ä¼¼ç‰©ä»¶å¹³å‡'],
                mode='markers',
                name='é¡ä¼¼ç‰©ä»¶å¹³å‡',
                marker=dict(size=8, color='#2ca02c', symbol='diamond')
            ))
        
        fig.update_layout(
            title=dict(text="<b>äºˆæ¸¬å±¥æ­´</b>", font=dict(size=18)),
            xaxis_title="æ—¥æ™‚",
            yaxis_title="ä¾¡æ ¼",
            template='plotly_white',
            height=400,
            hovermode='x unified'
        )
        
        return fig
    
    def get_statistics(self) -> dict:
        """å±¥æ­´ã®çµ±è¨ˆæƒ…å ±"""
        if not self.history:
            return {}
        
        predictions = [h['prediction'] for h in self.history]
        
        return {
            'äºˆæ¸¬å›æ•°': len(self.history),
            'å¹³å‡äºˆæ¸¬ä¾¡æ ¼': np.mean(predictions),
            'æœ€é«˜äºˆæ¸¬ä¾¡æ ¼': np.max(predictions),
            'æœ€ä½äºˆæ¸¬ä¾¡æ ¼': np.min(predictions),
            'æ¨™æº–åå·®': np.std(predictions)
        }
