"""
RealEstateMLStudio - ä¸å‹•ç”£ä¾¡æ ¼äºˆæ¸¬MLã‚¹ã‚¿ã‚¸ã‚ª
ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ v2.1 - ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ & å˜ç™ºäºˆæ¸¬æ©Ÿèƒ½è¿½åŠ 
"""
import streamlit as st
import pandas as pd
import numpy as np
import os
import sys

# srcãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from src.preprocessor import DataPreprocessor, get_data_summary
from src.trainer import ModelTrainer, StackingTrainer, compare_models, get_best_model
from src.visualizer import Visualizer
from src.utils import (
    load_css, create_header, init_session_state, 
    display_dataframe_info, show_success_message, show_warning_message
)

import warnings
warnings.filterwarnings('ignore')

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="RealEstateMLStudio",
    page_icon="ğŸ ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSSã®èª­ã¿è¾¼ã¿
load_css()

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
init_session_state()

# Visualizerã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
viz = Visualizer()


def load_sample_data(dataset_name: str) -> pd.DataFrame:
    """ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰"""
    
    if dataset_name == "california":
        # ã‚«ãƒªãƒ•ã‚©ãƒ«ãƒ‹ã‚¢ä½å®…ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
        from sklearn.datasets import fetch_california_housing
        data = fetch_california_housing()
        df = pd.DataFrame(data.data, columns=data.feature_names)
        df['MedHouseVal'] = data.target  # ä½å®…ä¾¡æ ¼ï¼ˆ10ä¸‡ãƒ‰ãƒ«å˜ä½ï¼‰
        
        # åˆ—åã‚’æ—¥æœ¬èªã«å¤‰æ›
        column_mapping = {
            'MedInc': 'ä¸–å¸¯åå…¥ä¸­å¤®å€¤',
            'HouseAge': 'ç¯‰å¹´æ•°',
            'AveRooms': 'å¹³å‡éƒ¨å±‹æ•°',
            'AveBedrms': 'å¹³å‡å¯å®¤æ•°',
            'Population': 'äººå£',
            'AveOccup': 'å¹³å‡ä¸–å¸¯äººæ•°',
            'Latitude': 'ç·¯åº¦',
            'Longitude': 'çµŒåº¦',
            'MedHouseVal': 'ä½å®…ä¾¡æ ¼'
        }
        df = df.rename(columns=column_mapping)
        return df
    
    elif dataset_name == "tokyo_sample":
        # æ±äº¬é¢¨ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ï¼ˆæ¶ç©ºãƒ‡ãƒ¼ã‚¿ï¼‰
        np.random.seed(42)
        n_samples = 1000
        
        # åŒºã®ãƒªã‚¹ãƒˆ
        districts = ['æ¸¯åŒº', 'æ¸‹è°·åŒº', 'æ–°å®¿åŒº', 'ä¸–ç”°è°·åŒº', 'ç›®é»’åŒº', 
                    'å“å·åŒº', 'å¤§ç”°åŒº', 'æ‰ä¸¦åŒº', 'ä¸­é‡åŒº', 'ç·´é¦¬åŒº']
        
        df = pd.DataFrame({
            'åŒº': np.random.choice(districts, n_samples),
            'ç¯‰å¹´æ•°': np.random.randint(0, 50, n_samples),
            'é¢ç©_m2': np.random.uniform(20, 150, n_samples).round(1),
            'éšæ•°': np.random.randint(1, 50, n_samples),
            'é§…å¾’æ­©åˆ†': np.random.randint(1, 20, n_samples),
            'éƒ¨å±‹æ•°': np.random.randint(1, 5, n_samples),
            'ãƒãƒ«ã‚³ãƒ‹ãƒ¼æœ‰': np.random.choice([0, 1], n_samples),
            'ã‚ªãƒ¼ãƒˆãƒ­ãƒƒã‚¯': np.random.choice([0, 1], n_samples),
        })
        
        # ä¾¡æ ¼ã‚’ç”Ÿæˆï¼ˆç‰¹å¾´é‡ã«åŸºã¥ãï¼‰
        base_price = 3000  # ä¸‡å††
        district_premium = {'æ¸¯åŒº': 2000, 'æ¸‹è°·åŒº': 1800, 'æ–°å®¿åŒº': 1500, 
                          'ä¸–ç”°è°·åŒº': 1200, 'ç›®é»’åŒº': 1400, 'å“å·åŒº': 1100,
                          'å¤§ç”°åŒº': 800, 'æ‰ä¸¦åŒº': 900, 'ä¸­é‡åŒº': 850, 'ç·´é¦¬åŒº': 700}
        
        df['ä¾¡æ ¼_ä¸‡å††'] = (
            base_price +
            df['åŒº'].map(district_premium) +
            df['é¢ç©_m2'] * 50 -
            df['ç¯‰å¹´æ•°'] * 30 +
            df['éšæ•°'] * 20 -
            df['é§…å¾’æ­©åˆ†'] * 50 +
            df['éƒ¨å±‹æ•°'] * 200 +
            df['ãƒãƒ«ã‚³ãƒ‹ãƒ¼æœ‰'] * 100 +
            df['ã‚ªãƒ¼ãƒˆãƒ­ãƒƒã‚¯'] * 150 +
            np.random.normal(0, 500, n_samples)
        ).round(0).astype(int)
        
        # ä¾¡æ ¼ã‚’æœ€ä½1000ä¸‡å††ã«
        df['ä¾¡æ ¼_ä¸‡å††'] = df['ä¾¡æ ¼_ä¸‡å††'].clip(lower=1000)
        
        return df
    
    elif dataset_name == "boston_simple":
        # ã‚·ãƒ³ãƒ—ãƒ«ãªä½å®…ãƒ‡ãƒ¼ã‚¿ï¼ˆæ¶ç©ºï¼‰
        np.random.seed(42)
        n_samples = 500
        
        df = pd.DataFrame({
            'RM': np.random.uniform(4, 9, n_samples).round(2),  # éƒ¨å±‹æ•°
            'LSTAT': np.random.uniform(2, 35, n_samples).round(2),  # ä½æ‰€å¾—è€…ç‡
            'PTRATIO': np.random.uniform(12, 22, n_samples).round(1),  # ç”Ÿå¾’æ•™å¸«æ¯”ç‡
            'DIS': np.random.uniform(1, 12, n_samples).round(2),  # éƒ½å¿ƒè·é›¢
            'NOX': np.random.uniform(0.4, 0.9, n_samples).round(3),  # å¤§æ°—æ±šæŸ“
            'AGE': np.random.uniform(10, 100, n_samples).round(1),  # ç¯‰å¹´æ•°
            'TAX': np.random.randint(180, 720, n_samples),  # å›ºå®šè³‡ç”£ç¨ç‡
            'CRIM': np.random.exponential(3, n_samples).round(3),  # çŠ¯ç½ªç‡
        })
        
        # ä¾¡æ ¼ã‚’ç”Ÿæˆ
        df['PRICE'] = (
            50 +
            df['RM'] * 5 -
            df['LSTAT'] * 0.5 -
            df['PTRATIO'] * 0.8 +
            df['DIS'] * 0.3 -
            df['NOX'] * 15 -
            df['AGE'] * 0.05 -
            df['TAX'] * 0.02 -
            df['CRIM'] * 0.3 +
            np.random.normal(0, 3, n_samples)
        ).round(1).clip(lower=5)
        
        # åˆ—åã‚’æ—¥æœ¬èªã«
        column_mapping = {
            'RM': 'éƒ¨å±‹æ•°',
            'LSTAT': 'ä½æ‰€å¾—è€…ç‡',
            'PTRATIO': 'ç”Ÿå¾’æ•™å¸«æ¯”ç‡',
            'DIS': 'éƒ½å¿ƒè·é›¢',
            'NOX': 'å¤§æ°—æ±šæŸ“æŒ‡æ•°',
            'AGE': 'ç¯‰å¹´æ•°',
            'TAX': 'å›ºå®šè³‡ç”£ç¨',
            'CRIM': 'çŠ¯ç½ªç‡',
            'PRICE': 'ä½å®…ä¾¡æ ¼'
        }
        df = df.rename(columns=column_mapping)
        return df
    
    return None


def create_prediction_form(feature_columns: list, df_original: pd.DataFrame) -> dict:
    """äºˆæ¸¬ç”¨ã®å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ã‚’ä½œæˆ"""
    
    st.subheader("ğŸ“ ç‰©ä»¶æƒ…å ±ã‚’å…¥åŠ›")
    
    input_data = {}
    
    # ç‰¹å¾´é‡ã‚’2åˆ—ã§è¡¨ç¤º
    col1, col2 = st.columns(2)
    
    for i, col in enumerate(feature_columns):
        # å…ƒã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰çµ±è¨ˆæƒ…å ±ã‚’å–å¾—
        if col in df_original.columns:
            col_data = df_original[col]
            
            # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã‹ã©ã†ã‹ã‚’åˆ¤å®š
            if col_data.dtype == 'object' or col_data.nunique() < 10:
                # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«: ã‚»ãƒ¬ã‚¯ãƒˆãƒœãƒƒã‚¯ã‚¹
                unique_values = col_data.unique().tolist()
                with col1 if i % 2 == 0 else col2:
                    input_data[col] = st.selectbox(
                        f"{col}",
                        options=unique_values,
                        key=f"input_{col}"
                    )
            else:
                # æ•°å€¤: ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã¾ãŸã¯æ•°å€¤å…¥åŠ›
                min_val = float(col_data.min())
                max_val = float(col_data.max())
                mean_val = float(col_data.mean())
                
                with col1 if i % 2 == 0 else col2:
                    # æ•´æ•°ã‹å°æ•°ã‹ã‚’åˆ¤å®š
                    if col_data.dtype in ['int64', 'int32']:
                        input_data[col] = st.number_input(
                            f"{col}",
                            min_value=int(min_val),
                            max_value=int(max_val * 1.5),
                            value=int(mean_val),
                            step=1,
                            key=f"input_{col}"
                        )
                    else:
                        input_data[col] = st.number_input(
                            f"{col}",
                            min_value=min_val * 0.5,
                            max_value=max_val * 1.5,
                            value=mean_val,
                            step=(max_val - min_val) / 100,
                            format="%.2f",
                            key=f"input_{col}"
                        )
        else:
            # å…ƒãƒ‡ãƒ¼ã‚¿ã«ãªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå…¥åŠ›
            with col1 if i % 2 == 0 else col2:
                input_data[col] = st.number_input(
                    f"{col}",
                    value=0.0,
                    key=f"input_{col}"
                )
    
    return input_data


def main():
    """ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³"""
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼ãƒãƒŠãƒ¼ç”»åƒ
    if os.path.exists("images/Appbanner.png"):
        st.image("images/Appbanner.png", use_container_width=True)
    else:
        # ãƒãƒŠãƒ¼ãŒãªã„å ´åˆã¯ãƒ†ã‚­ã‚¹ãƒˆãƒ˜ãƒƒãƒ€ãƒ¼
        create_header(
            "RealEstateMLStudio",
            "XGBoost / LightGBM / CatBoost / ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚° ã«ã‚ˆã‚‹é«˜ç²¾åº¦ä¸å‹•ç”£ä¾¡æ ¼äºˆæ¸¬"
        )
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    with st.sidebar:
        st.image("https://img.icons8.com/3d-fluency/94/home.png", width=80)
        st.title("è¨­å®šãƒ‘ãƒãƒ«")
        
        st.markdown("---")
        
        # ãƒ¢ãƒ‡ãƒ«é¸æŠ
        st.subheader("ğŸ¤– ãƒ¢ãƒ‡ãƒ«è¨­å®š")
        model_type = st.selectbox(
            "ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ é¸æŠ",
            ["XGBoost", "LightGBM", "CatBoost", "ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚° (ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«)", "å…¨ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ"],
            help="ä½¿ç”¨ã™ã‚‹æ©Ÿæ¢°å­¦ç¿’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’é¸æŠ"
        )
        
        # ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°è¨­å®š
        if model_type == "ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚° (ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«)":
            st.markdown("**ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°æ§‹æˆ**")
            use_xgb_stack = st.checkbox("XGBoost", value=True)
            use_lgb_stack = st.checkbox("LightGBM", value=True)
            use_cat_stack = st.checkbox("CatBoost", value=True)
        else:
            use_xgb_stack = use_lgb_stack = use_cat_stack = True
        
        # å…¨ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒæ™‚ã®ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°
        include_stacking = False
        if model_type == "å…¨ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ":
            include_stacking = st.checkbox("ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°ã‚‚å«ã‚ã‚‹", value=False)
        
        # ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°è¨­å®š
        st.subheader("âš™ï¸ ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°è¨­å®š")
        use_tuning = st.checkbox("ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°", value=False)
        
        if use_tuning:
            n_trials = st.slider("è©¦è¡Œå›æ•°", 10, 200, 50, 10)
        else:
            n_trials = 0
        
        # äº¤å·®æ¤œè¨¼è¨­å®š
        use_cv = st.checkbox("äº¤å·®æ¤œè¨¼ã‚’å®Ÿè¡Œ", value=True)
        if use_cv:
            cv_folds = st.slider("Foldæ•°", 3, 10, 5)
        else:
            cv_folds = 5
        
        # å‰å‡¦ç†è¨­å®š
        st.subheader("ğŸ”§ å‰å‡¦ç†è¨­å®š")
        handle_missing = st.checkbox("æ¬ æå€¤ã‚’è‡ªå‹•å‡¦ç†", value=True)
        encode_categorical = st.checkbox("ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰", value=True)
        handle_outliers = st.checkbox("ç•°å¸¸å€¤ã‚’å‡¦ç†", value=False)
        scale_features = st.checkbox("ç‰¹å¾´é‡ã‚’ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°", value=False)
        
        # CatBoostç”¨è¨­å®š
        if model_type == "CatBoost":
            st.subheader("ğŸ± CatBoostè¨­å®š")
            use_native_cat = st.checkbox(
                "ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã‚’ãƒã‚¤ãƒ†ã‚£ãƒ–å‡¦ç†", 
                value=True,
                help="CatBoostã®ãƒã‚¤ãƒ†ã‚£ãƒ–ã‚«ãƒ†ã‚´ãƒªå‡¦ç†ã‚’ä½¿ç”¨ï¼ˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ä¸è¦ï¼‰"
            )
            if use_native_cat:
                encode_categorical = False
        else:
            use_native_cat = False
        
        st.markdown("---")
        
        # ãƒ¢ãƒ‡ãƒ«ä¿å­˜/èª­ã¿è¾¼ã¿
        st.subheader("ğŸ’¾ ãƒ¢ãƒ‡ãƒ«ç®¡ç†")
        if st.session_state.get('is_trained', False):
            if st.button("ğŸ“¥ ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜"):
                save_model()
        
        uploaded_model = st.file_uploader("ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿", type=['joblib'])
        if uploaded_model:
            load_saved_model(uploaded_model)
    
    # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
    tabs = st.tabs([
        "ğŸ“¤ ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", 
        "ğŸ” ãƒ‡ãƒ¼ã‚¿åˆ†æ (EDA)", 
        "ğŸ¯ ãƒ¢ãƒ‡ãƒ«å­¦ç¿’",
        "ğŸ“Š è©•ä¾¡çµæœ",
        "ğŸ”® äºˆæ¸¬å®Ÿè¡Œ"
    ])
    
    # ã‚¿ãƒ–1: ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    with tabs[0]:
        st.header("Step 1: ãƒ‡ãƒ¼ã‚¿ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.markdown("""
            <div class="info-card">
                <strong>ğŸ“‹ å¯¾å¿œãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ</strong><br>
                CSVå½¢å¼ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‰ãƒ©ãƒƒã‚°ï¼†ãƒ‰ãƒ­ãƒƒãƒ—ã—ã¦ãã ã•ã„ã€‚<br>
                ãƒ»æ•™å¸«ã‚ã‚Šå­¦ç¿’ç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆç›®çš„å¤‰æ•°ã‚’å«ã‚€ï¼‰<br>
                ãƒ»æ¬ æå€¤ã‚„ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã¯è‡ªå‹•ã§å‡¦ç†ã•ã‚Œã¾ã™
            </div>
            """, unsafe_allow_html=True)
            
            uploaded_file = st.file_uploader(
                "å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
                type=['csv'],
                help="CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‰ãƒ©ãƒƒã‚°ï¼†ãƒ‰ãƒ­ãƒƒãƒ—"
            )
        
        with col2:
            st.markdown("""
            <div class="metric-card">
                <div style="font-size: 3rem;">ğŸ“Š</div>
                <div class="metric-label">ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦<br>åˆ†æã‚’é–‹å§‹ã—ã¾ã—ã‚‡ã†</div>
            </div>
            """, unsafe_allow_html=True)
        
        # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ã‚¯ã‚·ãƒ§ãƒ³
        st.markdown("---")
        st.subheader("ğŸ® ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã§è©¦ã™")
        st.markdown("ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯ã€ä»¥ä¸‹ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã‚¢ãƒ—ãƒªã®æ©Ÿèƒ½ã‚’è©¦ã™ã“ã¨ãŒã§ãã¾ã™ã€‚")
        
        sample_col1, sample_col2, sample_col3 = st.columns(3)
        
        with sample_col1:
            st.markdown("""
            **ğŸŒ´ ã‚«ãƒªãƒ•ã‚©ãƒ«ãƒ‹ã‚¢ä½å®…**
            - 20,640ä»¶ã®ãƒ‡ãƒ¼ã‚¿
            - 8ã¤ã®ç‰¹å¾´é‡
            - ä½å®…ä¾¡æ ¼ï¼ˆä¸­å¤®å€¤ï¼‰ã‚’äºˆæ¸¬
            """)
            if st.button("ğŸ“¥ ã‚«ãƒªãƒ•ã‚©ãƒ«ãƒ‹ã‚¢ä½å®…ãƒ‡ãƒ¼ã‚¿", key="load_california"):
                df = load_sample_data("california")
                st.session_state['df'] = df
                st.session_state['sample_data_name'] = 'ã‚«ãƒªãƒ•ã‚©ãƒ«ãƒ‹ã‚¢ä½å®…'
                st.rerun()
        
        with sample_col2:
            st.markdown("""
            **ğŸ—¼ æ±äº¬ãƒãƒ³ã‚·ãƒ§ãƒ³ï¼ˆæ¶ç©ºï¼‰**
            - 1,000ä»¶ã®ãƒ‡ãƒ¼ã‚¿
            - åŒºãƒ»é¢ç©ãƒ»ç¯‰å¹´æ•°ãªã©
            - ãƒãƒ³ã‚·ãƒ§ãƒ³ä¾¡æ ¼ã‚’äºˆæ¸¬
            """)
            if st.button("ğŸ“¥ æ±äº¬ãƒãƒ³ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿", key="load_tokyo"):
                df = load_sample_data("tokyo_sample")
                st.session_state['df'] = df
                st.session_state['sample_data_name'] = 'æ±äº¬ãƒãƒ³ã‚·ãƒ§ãƒ³'
                st.rerun()
        
        with sample_col3:
            st.markdown("""
            **ğŸ˜ï¸ ã‚·ãƒ³ãƒ—ãƒ«ä½å®…ãƒ‡ãƒ¼ã‚¿**
            - 500ä»¶ã®ãƒ‡ãƒ¼ã‚¿
            - éƒ¨å±‹æ•°ãƒ»ç¯‰å¹´æ•°ãªã©
            - ä½å®…ä¾¡æ ¼ã‚’äºˆæ¸¬
            """)
            if st.button("ğŸ“¥ ã‚·ãƒ³ãƒ—ãƒ«ä½å®…ãƒ‡ãƒ¼ã‚¿", key="load_boston"):
                df = load_sample_data("boston_simple")
                st.session_state['df'] = df
                st.session_state['sample_data_name'] = 'ã‚·ãƒ³ãƒ—ãƒ«ä½å®…'
                st.rerun()
        
        # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†
        if uploaded_file:
            df = pd.read_csv(uploaded_file)
            st.session_state['df'] = df
            st.session_state['sample_data_name'] = None
        
        # ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚ŒãŸå ´åˆã®è¡¨ç¤º
        if st.session_state.get('df') is not None:
            df = st.session_state['df']
            
            # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®å ´åˆã¯åå‰ã‚’è¡¨ç¤º
            if st.session_state.get('sample_data_name'):
                show_success_message(f"ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã€Œ{st.session_state['sample_data_name']}ã€ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {len(df):,}è¡Œ Ã— {len(df.columns)}åˆ—")
            else:
                show_success_message(f"ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {len(df):,}è¡Œ Ã— {len(df.columns)}åˆ—")
            
            # ãƒ‡ãƒ¼ã‚¿æƒ…å ±ã®è¡¨ç¤º
            display_dataframe_info(df)
            
            st.markdown("---")
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
            st.subheader("ğŸ“‹ ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
            st.dataframe(df.head(20), use_container_width=True, height=400)
            
            # ã‚«ãƒ©ãƒ æƒ…å ±
            col1, col2 = st.columns(2)
            with col1:
                st.subheader("ğŸ”¢ æ•°å€¤åˆ—")
                numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
                st.write(numeric_cols)
            with col2:
                st.subheader("ğŸ“ ã‚«ãƒ†ã‚´ãƒªåˆ—")
                cat_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()
                st.write(cat_cols if cat_cols else "ãªã—")
    
    # ã‚¿ãƒ–2: ãƒ‡ãƒ¼ã‚¿åˆ†æ (EDA)
    with tabs[1]:
        st.header("Step 2: æ¢ç´¢çš„ãƒ‡ãƒ¼ã‚¿åˆ†æ (EDA)")
        
        if st.session_state.get('df') is not None:
            df = st.session_state['df']
            
            # åŸºæœ¬çµ±è¨ˆé‡
            st.subheader("ğŸ“ˆ åŸºæœ¬çµ±è¨ˆé‡")
            st.dataframe(df.describe(), use_container_width=True)
            
            # æ¬ æå€¤åˆ†æ
            st.subheader("ğŸ” æ¬ æå€¤åˆ†æ")
            missing = df.isnull().sum()
            missing_pct = (missing / len(df) * 100).round(2)
            missing_df = pd.DataFrame({
                'æ¬ ææ•°': missing,
                'æ¬ æç‡ (%)': missing_pct
            }).sort_values('æ¬ ææ•°', ascending=False)
            
            col1, col2 = st.columns([1, 2])
            with col1:
                st.dataframe(missing_df[missing_df['æ¬ ææ•°'] > 0], use_container_width=True)
            with col2:
                if missing.sum() > 0:
                    fig = viz.plot_feature_importance(
                        missing[missing > 0].sort_values(ascending=False),
                        top_n=20,
                        title="æ¬ æå€¤ã®åˆ†å¸ƒ"
                    )
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    st.success("âœ… æ¬ æå€¤ã¯ã‚ã‚Šã¾ã›ã‚“")
            
            # ç›¸é–¢è¡Œåˆ—
            st.subheader("ğŸ”— ç‰¹å¾´é‡ç›¸é–¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹")
            fig_corr = viz.plot_eda_dashboard(df)
            if fig_corr:
                st.plotly_chart(fig_corr, use_container_width=True)
            
            # åˆ†å¸ƒã®å¯è¦–åŒ–
            st.subheader("ğŸ“Š æ•°å€¤å¤‰æ•°ã®åˆ†å¸ƒ")
            numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
            
            if numeric_cols:
                selected_col = st.selectbox("è¡¨ç¤ºã™ã‚‹åˆ—ã‚’é¸æŠ", numeric_cols)
                
                import plotly.express as px
                fig = px.histogram(
                    df, x=selected_col, 
                    nbins=50,
                    title=f"{selected_col} ã®åˆ†å¸ƒ",
                    marginal="box"
                )
                fig.update_layout(template='plotly_white')
                st.plotly_chart(fig, use_container_width=True)
        else:
            show_warning_message("å…ˆã«ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
    
    # ã‚¿ãƒ–3: ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
    with tabs[2]:
        st.header("Step 3: ãƒ¢ãƒ‡ãƒ«å­¦ç¿’")
        
        if st.session_state.get('df') is not None:
            df = st.session_state['df']
            
            col1, col2 = st.columns(2)
            
            with col1:
                # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ—é¸æŠ
                target_column = st.selectbox(
                    "ğŸ¯ ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ—ï¼ˆäºˆæ¸¬ã—ãŸã„åˆ—ï¼‰",
                    df.columns.tolist(),
                    index=len(df.columns) - 1
                )
                st.session_state['target_column'] = target_column
            
            with col2:
                # ãƒ†ã‚¹ãƒˆã‚µã‚¤ã‚º
                test_size = st.slider("ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®å‰²åˆ", 0.1, 0.4, 0.2, 0.05)
            
            # ãƒ¢ãƒ‡ãƒ«æƒ…å ±è¡¨ç¤º
            st.markdown("---")
            
            model_info = {
                "XGBoost": "ğŸš€ é«˜ç²¾åº¦ãªå‹¾é…ãƒ–ãƒ¼ã‚¹ãƒ†ã‚£ãƒ³ã‚°ã€‚ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸæ€§èƒ½ã€‚",
                "LightGBM": "âš¡ é«˜é€Ÿãƒ»è»½é‡ã€‚å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã«æœ€é©ã€‚",
                "CatBoost": "ğŸ± ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã«å¼·ã„ã€‚éå­¦ç¿’ã—ã«ãã„ã€‚",
                "ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚° (ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«)": "ğŸ† è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã‚’çµ„ã¿åˆã‚ã›æœ€é«˜ç²¾åº¦ã‚’å®Ÿç¾ã€‚",
                "å…¨ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ": "ğŸ“Š å…¨ãƒ¢ãƒ‡ãƒ«ã‚’æ¯”è¼ƒã—ã¦æœ€é©ãªã‚‚ã®ã‚’é¸æŠã€‚"
            }
            
            st.info(f"**é¸æŠä¸­ã®ãƒ¢ãƒ‡ãƒ«**: {model_type}\n\n{model_info[model_type]}")
            
            # å‰å‡¦ç†å®Ÿè¡Œ
            st.markdown("---")
            st.subheader("ğŸ”§ ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†")
            
            if st.button("å‰å‡¦ç†ã‚’å®Ÿè¡Œ", key="preprocess_btn"):
                with st.spinner("å‰å‡¦ç†ä¸­..."):
                    preprocessor = DataPreprocessor()
                    
                    # CatBoostã§ãƒã‚¤ãƒ†ã‚£ãƒ–å‡¦ç†ã‚’ä½¿ã†å ´åˆã¯ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ãªã„
                    actual_encode = encode_categorical and not (model_type == "CatBoost" and use_native_cat)
                    
                    df_processed = preprocessor.auto_preprocess(
                        df,
                        target_column=target_column,
                        handle_missing=handle_missing,
                        encode_cat=actual_encode,
                        handle_outliers_flag=handle_outliers,
                        scale=scale_features
                    )
                    
                    st.session_state['df_processed'] = df_processed
                    st.session_state['preprocessor'] = preprocessor
                    st.session_state['df_original'] = df.copy()  # å…ƒã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
                    st.session_state['use_native_cat'] = use_native_cat if model_type == "CatBoost" else False
                    
                    show_success_message("å‰å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                    
                    # å‰å‡¦ç†å¾Œã®ãƒ‡ãƒ¼ã‚¿æƒ…å ±
                    st.write("å‰å‡¦ç†å¾Œã®ãƒ‡ãƒ¼ã‚¿:")
                    display_dataframe_info(df_processed)
                    st.dataframe(df_processed.head(10), use_container_width=True)
            
            # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
            st.markdown("---")
            st.subheader("ğŸš€ ãƒ¢ãƒ‡ãƒ«å­¦ç¿’")
            
            if st.session_state.get('df_processed') is not None:
                if st.button("ğŸ“ å­¦ç¿’é–‹å§‹", type="primary", key="train_btn"):
                    train_model(
                        model_type, 
                        use_tuning, 
                        n_trials, 
                        use_cv, 
                        cv_folds, 
                        test_size,
                        use_xgb_stack,
                        use_lgb_stack,
                        use_cat_stack,
                        include_stacking
                    )
            else:
                st.info("ğŸ‘† ã¾ãšå‰å‡¦ç†ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
        else:
            show_warning_message("å…ˆã«ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
    
    # ã‚¿ãƒ–4: è©•ä¾¡çµæœ
    with tabs[3]:
        st.header("Step 4: ãƒ¢ãƒ‡ãƒ«è©•ä¾¡")
        
        if st.session_state.get('is_trained', False):
            trainer = st.session_state['trainer']
            metrics = st.session_state['metrics']
            
            # è©•ä¾¡æŒ‡æ¨™ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
            st.subheader("ğŸ“Š è©•ä¾¡æŒ‡æ¨™ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
            fig_metrics = viz.plot_metrics_dashboard(metrics, getattr(trainer, 'cv_scores', None))
            st.plotly_chart(fig_metrics, use_container_width=True)
            
            # å®Ÿæ¸¬å€¤ vs äºˆæ¸¬å€¤
            st.subheader("ğŸ¯ å®Ÿæ¸¬å€¤ vs äºˆæ¸¬å€¤")
            y_test_vals = trainer.y_test.values if hasattr(trainer.y_test, 'values') else trainer.y_test
            fig_pred = viz.plot_actual_vs_predicted(y_test_vals, trainer.y_pred)
            st.plotly_chart(fig_pred, use_container_width=True)
            
            # æ®‹å·®åˆ†æ
            st.subheader("ğŸ“ˆ æ®‹å·®åˆ†æ")
            fig_residuals = viz.plot_residuals(y_test_vals, trainer.y_pred)
            st.plotly_chart(fig_residuals, use_container_width=True)
            
            # ç‰¹å¾´é‡é‡è¦åº¦
            if trainer.feature_importance is not None:
                st.subheader("ğŸ”‘ ç‰¹å¾´é‡é‡è¦åº¦")
                fig_importance = viz.plot_feature_importance(
                    trainer.feature_importance,
                    top_n=min(20, len(trainer.feature_importance))
                )
                st.plotly_chart(fig_importance, use_container_width=True)
            
            # äº¤å·®æ¤œè¨¼çµæœ
            if hasattr(trainer, 'cv_scores') and trainer.cv_scores:
                st.subheader("ğŸ”„ äº¤å·®æ¤œè¨¼çµæœ")
                fig_cv = viz.plot_cv_results(trainer.cv_scores)
                st.plotly_chart(fig_cv, use_container_width=True)
            
            # ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒçµæœ
            if st.session_state.get('comparison_results'):
                st.subheader("âš–ï¸ ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ")
                comparison = st.session_state['comparison_results']
                fig_compare = viz.plot_model_comparison(comparison['comparison_df'])
                st.plotly_chart(fig_compare, use_container_width=True)
                
                st.dataframe(comparison['comparison_df'], use_container_width=True)
                
                # æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã‚’è¡¨ç¤º
                best = get_best_model(comparison)
                st.success(f"ğŸ† æœ€è‰¯ãƒ¢ãƒ‡ãƒ«: **{best.upper()}** (RÂ² = {comparison[best]['metrics']['r2']:.4f})")
            
            # äºˆæ¸¬å€¤åˆ†å¸ƒ
            st.subheader("ğŸ“Š äºˆæ¸¬å€¤ã¨å®Ÿæ¸¬å€¤ã®åˆ†å¸ƒ")
            fig_dist = viz.plot_prediction_distribution(y_test_vals, trainer.y_pred)
            st.plotly_chart(fig_dist, use_container_width=True)
            
        else:
            show_warning_message("å…ˆã«ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã—ã¦ãã ã•ã„")
    
    # ã‚¿ãƒ–5: äºˆæ¸¬å®Ÿè¡Œ
    with tabs[4]:
        st.header("Step 5: æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã§äºˆæ¸¬")
        
        if st.session_state.get('is_trained', False):
            
            # äºˆæ¸¬æ–¹æ³•ã®é¸æŠ
            pred_method = st.radio(
                "äºˆæ¸¬æ–¹æ³•ã‚’é¸æŠ",
                ["ğŸ“ CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ä¸€æ‹¬äºˆæ¸¬", "ğŸ“ æ‰‹å…¥åŠ›ã§äºˆæ¸¬"],
                horizontal=True
            )
            
            st.markdown("---")
            
            if pred_method == "ğŸ“ CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ä¸€æ‹¬äºˆæ¸¬":
                # æ—¢å­˜ã®CSVã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰äºˆæ¸¬
                st.markdown("""
                <div class="info-card">
                    <strong>ğŸ“‹ äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™</strong><br>
                    å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨åŒã˜å½¢å¼ï¼ˆåŒã˜åˆ—åãƒ»é †åºï¼‰ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚<br>
                    â€»ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ—ã¯å«ã¾ãªãã¦OKã§ã™
                </div>
                """, unsafe_allow_html=True)
                
                pred_file = st.file_uploader(
                    "äºˆæ¸¬ã—ãŸã„ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
                    type=['csv'],
                    key="pred_uploader"
                )
                
                if pred_file:
                    df_pred = pd.read_csv(pred_file)
                    
                    st.subheader("ğŸ“‹ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿")
                    st.dataframe(df_pred.head(10), use_container_width=True)
                    
                    if st.button("ğŸ”® äºˆæ¸¬å®Ÿè¡Œ", type="primary", key="batch_predict"):
                        with st.spinner("äºˆæ¸¬ä¸­..."):
                            try:
                                # å‰å‡¦ç†ï¼ˆå­¦ç¿’æ™‚ã¨åŒã˜å¤‰æ›ã‚’é©ç”¨ï¼‰
                                preprocessor = st.session_state.get('preprocessor')
                                if preprocessor and not st.session_state.get('use_native_cat', False):
                                    df_pred_processed = preprocessor.transform_new_data(df_pred)
                                else:
                                    df_pred_processed = df_pred
                                
                                # äºˆæ¸¬å®Ÿè¡Œ
                                trainer = st.session_state['trainer']
                                predictions = trainer.predict(df_pred_processed)
                                
                                # çµæœã‚’è¡¨ç¤º
                                df_result = df_pred.copy()
                                df_result['äºˆæ¸¬å€¤'] = predictions
                                
                                show_success_message("äºˆæ¸¬ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                                
                                st.subheader("ğŸ“Š äºˆæ¸¬çµæœ")
                                st.dataframe(df_result, use_container_width=True, height=400)
                                
                                # çµ±è¨ˆã‚µãƒãƒªãƒ¼
                                col1, col2, col3, col4 = st.columns(4)
                                with col1:
                                    st.metric("å¹³å‡äºˆæ¸¬å€¤", f"{predictions.mean():,.2f}")
                                with col2:
                                    st.metric("æœ€å°äºˆæ¸¬å€¤", f"{predictions.min():,.2f}")
                                with col3:
                                    st.metric("æœ€å¤§äºˆæ¸¬å€¤", f"{predictions.max():,.2f}")
                                with col4:
                                    st.metric("æ¨™æº–åå·®", f"{predictions.std():,.2f}")
                                
                                # CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                                csv = df_result.to_csv(index=False).encode('utf-8-sig')
                                st.download_button(
                                    "ğŸ“¥ äºˆæ¸¬çµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                                    csv,
                                    "prediction_results.csv",
                                    "text/csv"
                                )
                                
                            except Exception as e:
                                st.error(f"äºˆæ¸¬ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            
            else:
                # å˜ç™ºäºˆæ¸¬ãƒ•ã‚©ãƒ¼ãƒ 
                st.markdown("""
                <div class="info-card">
                    <strong>ğŸ“ æ‰‹å…¥åŠ›ã§äºˆæ¸¬</strong><br>
                    ç‰©ä»¶æƒ…å ±ã‚’å…¥åŠ›ã—ã¦ã€ä¾¡æ ¼ã‚’äºˆæ¸¬ã—ã¾ã™ã€‚
                </div>
                """, unsafe_allow_html=True)
                
                # ç‰¹å¾´é‡åˆ—ã‚’å–å¾—
                feature_columns = st.session_state.get('feature_columns', [])
                df_original = st.session_state.get('df_original', st.session_state.get('df'))
                
                if feature_columns and df_original is not None:
                    # å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ã‚’ä½œæˆ
                    input_data = create_prediction_form(feature_columns, df_original)
                    
                    st.markdown("---")
                    
                    # äºˆæ¸¬ãƒœã‚¿ãƒ³
                    if st.button("ğŸ”® ã“ã®ç‰©ä»¶ã®ä¾¡æ ¼ã‚’äºˆæ¸¬", type="primary", key="single_predict"):
                        with st.spinner("äºˆæ¸¬ä¸­..."):
                            try:
                                # å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã‚’DataFrameã«å¤‰æ›
                                df_input = pd.DataFrame([input_data])
                                
                                # å‰å‡¦ç†
                                preprocessor = st.session_state.get('preprocessor')
                                if preprocessor and not st.session_state.get('use_native_cat', False):
                                    df_input_processed = preprocessor.transform_new_data(df_input)
                                else:
                                    df_input_processed = df_input
                                
                                # æ•°å€¤åˆ—ã®ã¿ã‚’ä½¿ç”¨ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
                                if not st.session_state.get('use_native_cat', False):
                                    df_input_processed = df_input_processed.select_dtypes(include=[np.number])
                                
                                # äºˆæ¸¬å®Ÿè¡Œ
                                trainer = st.session_state['trainer']
                                prediction = trainer.predict(df_input_processed)[0]
                                
                                # çµæœã‚’è¡¨ç¤º
                                st.markdown("---")
                                st.subheader("ğŸ‰ äºˆæ¸¬çµæœ")
                                
                                # å¤§ããäºˆæ¸¬å€¤ã‚’è¡¨ç¤º
                                target_column = st.session_state.get('target_column', 'ä¾¡æ ¼')
                                
                                st.markdown(f"""
                                <div style="
                                    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                                    border-radius: 20px;
                                    padding: 40px;
                                    text-align: center;
                                    color: white;
                                    margin: 20px 0;
                                    box-shadow: 0 10px 30px rgba(0,0,0,0.2);
                                ">
                                    <h2 style="margin: 0; font-size: 1.2rem; opacity: 0.9;">äºˆæ¸¬ {target_column}</h2>
                                    <h1 style="margin: 10px 0; font-size: 3.5rem; font-weight: bold;">
                                        {prediction:,.2f}
                                    </h1>
                                </div>
                                """, unsafe_allow_html=True)
                                
                                # å…¥åŠ›ã—ãŸæ¡ä»¶ã‚’è¡¨ç¤º
                                st.subheader("ğŸ“‹ å…¥åŠ›æ¡ä»¶")
                                col1, col2 = st.columns(2)
                                items = list(input_data.items())
                                mid = len(items) // 2
                                
                                with col1:
                                    for key, value in items[:mid]:
                                        st.write(f"**{key}**: {value}")
                                with col2:
                                    for key, value in items[mid:]:
                                        st.write(f"**{key}**: {value}")
                                
                            except Exception as e:
                                st.error(f"äºˆæ¸¬ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                                st.write("ãƒ‡ãƒãƒƒã‚°æƒ…å ±:", str(e))
                else:
                    st.warning("ç‰¹å¾´é‡æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ¢ãƒ‡ãƒ«ã‚’å†å­¦ç¿’ã—ã¦ãã ã•ã„ã€‚")
        else:
            show_warning_message("å…ˆã«ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã—ã¦ãã ã•ã„")


def train_model(model_type, use_tuning, n_trials, use_cv, cv_folds, test_size,
                use_xgb_stack=True, use_lgb_stack=True, use_cat_stack=True,
                include_stacking=False):
    """ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã‚’å®Ÿè¡Œ"""
    
    df_processed = st.session_state['df_processed']
    target_column = st.session_state['target_column']
    
    # ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚’åˆ†é›¢
    X = df_processed.drop(columns=[target_column])
    y = df_processed[target_column]
    
    # CatBoostã§ãƒã‚¤ãƒ†ã‚£ãƒ–ã‚«ãƒ†ã‚´ãƒªã‚’ä½¿ã‚ãªã„å ´åˆã¯æ•°å€¤åˆ—ã®ã¿
    use_native_cat = st.session_state.get('use_native_cat', False)
    if not use_native_cat:
        X = X.select_dtypes(include=[np.number])
    
    st.session_state['feature_columns'] = X.columns.tolist()
    
    # ã‚«ãƒ†ã‚´ãƒªåˆ—ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—ï¼ˆCatBoostç”¨ï¼‰
    cat_features = None
    if use_native_cat:
        cat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()
        if cat_cols:
            cat_features = [X.columns.get_loc(col) for col in cat_cols]
    
    # ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒãƒ¢ãƒ¼ãƒ‰
    if model_type == "å…¨ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ":
        with st.spinner("å…¨ãƒ¢ãƒ‡ãƒ«ã‚’æ¯”è¼ƒä¸­..."):
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
            from sklearn.model_selection import train_test_split
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=test_size, random_state=42
            )
            
            status_text.text("ãƒ¢ãƒ‡ãƒ«ã‚’æ¯”è¼ƒä¸­...")
            progress_bar.progress(30)
            
            # æ¯”è¼ƒå®Ÿè¡Œï¼ˆæ•°å€¤åˆ—ã®ã¿ã§ï¼‰
            X_train_num = X_train.select_dtypes(include=[np.number])
            X_test_num = X_test.select_dtypes(include=[np.number])
            
            comparison_results = compare_models(
                X_train_num, X_test_num, y_train, y_test,
                include_stacking=include_stacking
            )
            
            progress_bar.progress(100)
            status_text.text("å®Œäº†ï¼")
            
            # æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ
            best_model_type = get_best_model(comparison_results)
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
            trainer = ModelTrainer()
            trainer.model = comparison_results[best_model_type]['model']
            trainer.model_type = best_model_type
            trainer.feature_importance = comparison_results[best_model_type]['feature_importance']
            trainer.y_pred = comparison_results[best_model_type]['predictions']
            trainer.y_test = y_test
            
            st.session_state['trainer'] = trainer
            st.session_state['metrics'] = comparison_results[best_model_type]['metrics']
            st.session_state['is_trained'] = True
            st.session_state['comparison_results'] = comparison_results
            
            show_success_message(f"æ¯”è¼ƒå®Œäº†ï¼æœ€è‰¯ãƒ¢ãƒ‡ãƒ«: {best_model_type.upper()}")
            
            # æ¯”è¼ƒè¡¨ã‚’è¡¨ç¤º
            st.dataframe(comparison_results['comparison_df'], use_container_width=True)
    
    # ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰
    elif model_type == "ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚° (ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«)":
        with st.spinner("ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ä¸­..."):
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
            from sklearn.model_selection import train_test_split
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=test_size, random_state=42
            )
            
            # æ•°å€¤åˆ—ã®ã¿ä½¿ç”¨
            X_train_num = X_train.select_dtypes(include=[np.number])
            X_test_num = X_test.select_dtypes(include=[np.number])
            
            status_text.text("ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ä¸­...")
            progress_bar.progress(30)
            
            stacking_trainer = StackingTrainer()
            stacking_trainer.train(
                X_train_num, y_train,
                use_xgboost=use_xgb_stack,
                use_lightgbm=use_lgb_stack,
                use_catboost=use_cat_stack,
                cv_folds=cv_folds
            )
            
            progress_bar.progress(80)
            status_text.text("è©•ä¾¡ä¸­...")
            
            metrics = stacking_trainer.evaluate(X_test_num, y_test)
            
            progress_bar.progress(100)
            status_text.text("å®Œäº†ï¼")
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
            st.session_state['trainer'] = stacking_trainer
            st.session_state['metrics'] = metrics
            st.session_state['is_trained'] = True
            st.session_state['model_type'] = 'stacking'
            
            show_success_message("ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
            
            # çµæœè¡¨ç¤º
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("RÂ² Score", f"{metrics['r2']:.4f}")
            with col2:
                st.metric("RMSE", f"{metrics['rmse']:.4f}")
            with col3:
                st.metric("MAE", f"{metrics['mae']:.4f}")
            with col4:
                st.metric("MAPE", f"{metrics['mape']:.2f}%")
            
    else:
        # å˜ä¸€ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
        trainer = ModelTrainer()
        
        model_map = {
            'XGBoost': 'xgboost',
            'LightGBM': 'lightgbm',
            'CatBoost': 'catboost'
        }
        selected_model = model_map[model_type]
        
        # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
        X_train, X_test, y_train, y_test = trainer.prepare_data(X, y, test_size=test_size)
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
        if use_tuning:
            status_text.text(f"ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­... ({n_trials}è©¦è¡Œ)")
            
            # ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ã¯æ•°å€¤åˆ—ã®ã¿
            X_train_num = X_train.select_dtypes(include=[np.number])
            
            def update_progress(progress):
                progress_bar.progress(int(progress * 50))
            
            tuning_results = trainer.tune_hyperparameters(
                X_train_num, y_train,
                model_type=selected_model,
                n_trials=n_trials,
                cv_folds=cv_folds,
                progress_callback=update_progress
            )
            
            st.write("æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:", tuning_results['best_params'])
            progress_bar.progress(50)
        else:
            progress_bar.progress(25)
        
        # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
        status_text.text("ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ä¸­...")
        
        # CatBoostä»¥å¤–ã¯æ•°å€¤åˆ—ã®ã¿
        if selected_model != 'catboost' or not use_native_cat:
            X_train_fit = X_train.select_dtypes(include=[np.number])
            X_test_fit = X_test.select_dtypes(include=[np.number])
            trainer.train(X_train_fit, y_train, model_type=selected_model, use_default_params=not use_tuning)
        else:
            X_train_fit = X_train
            X_test_fit = X_test
            trainer.train(X_train_fit, y_train, model_type=selected_model, 
                         use_default_params=not use_tuning, cat_features=cat_features)
        
        progress_bar.progress(70)
        
        # äº¤å·®æ¤œè¨¼
        if use_cv:
            status_text.text("äº¤å·®æ¤œè¨¼ã‚’å®Ÿè¡Œä¸­...")
            X_cv = X.select_dtypes(include=[np.number]) if selected_model != 'catboost' or not use_native_cat else X
            cv_scores = trainer.cross_validate(X_cv, y, cv_folds=cv_folds)
            st.write(f"CV RÂ² Score: {cv_scores['r2_mean']:.4f} (Â±{cv_scores['r2_std']:.4f})")
        
        progress_bar.progress(90)
        
        # è©•ä¾¡
        status_text.text("ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ä¸­...")
        metrics = trainer.evaluate(X_test_fit, y_test)
        trainer.y_test = y_test
        
        progress_bar.progress(100)
        status_text.text("å®Œäº†ï¼")
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
        st.session_state['trainer'] = trainer
        st.session_state['metrics'] = metrics
        st.session_state['is_trained'] = True
        st.session_state['model_type'] = selected_model
        
        show_success_message(f"{model_type} ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        
        # ç°¡æ˜“çµæœè¡¨ç¤º
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("RÂ² Score", f"{metrics['r2']:.4f}")
        with col2:
            st.metric("RMSE", f"{metrics['rmse']:.4f}")
        with col3:
            st.metric("MAE", f"{metrics['mae']:.4f}")
        with col4:
            st.metric("MAPE", f"{metrics['mape']:.2f}%")


def save_model():
    """ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜"""
    trainer = st.session_state['trainer']
    
    # modelsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜
    from datetime import datetime
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    model_type = st.session_state.get('model_type', 'model')
    filename = f"model_{model_type}_{timestamp}.joblib"
    filepath = os.path.join('models', filename)
    
    try:
        trainer.save_model(filepath)
        show_success_message(f"ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {filename}")
    except Exception as e:
        st.error(f"ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")


def load_saved_model(uploaded_model):
    """ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
    try:
        import joblib
        import tempfile
        
        with tempfile.NamedTemporaryFile(delete=False, suffix='.joblib') as tmp:
            tmp.write(uploaded_model.getvalue())
            tmp_path = tmp.name
        
        trainer = ModelTrainer()
        model_data = trainer.load_model(tmp_path)
        
        st.session_state['trainer'] = trainer
        st.session_state['metrics'] = model_data['metrics']
        st.session_state['is_trained'] = True
        st.session_state['model_type'] = model_data['model_type']
        
        show_success_message(f"ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {model_data['model_type']}")
        
        os.unlink(tmp_path)
        
    except Exception as e:
        st.error(f"èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")


if __name__ == "__main__":
    main()
