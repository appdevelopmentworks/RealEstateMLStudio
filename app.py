"""
RealEstateMLStudio - ä¸å‹•ç”£ä¾¡æ ¼äºˆæ¸¬MLã‚¹ã‚¿ã‚¸ã‚ª
ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ v2.2 - SHAPåˆ†æãƒ»ä¿¡é ¼åŒºé–“ãƒ»PDFãƒ¬ãƒãƒ¼ãƒˆãƒ»What-ifåˆ†æ
"""
import streamlit as st
import pandas as pd
import numpy as np
import os
import sys

# srcãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from src.preprocessor import DataPreprocessor, get_data_summary
from src.trainer import ModelTrainer, StackingTrainer, compare_models, get_best_model
from src.visualizer import Visualizer
from src.analysis import SHAPAnalyzer, PredictionInterval, WhatIfAnalyzer, PDFReportGenerator
from src.utils import (
    load_css, create_header, init_session_state, 
    display_dataframe_info, show_success_message, show_warning_message
)

import warnings
warnings.filterwarnings('ignore')

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="RealEstateMLStudio",
    page_icon="ğŸ ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSSã®èª­ã¿è¾¼ã¿
load_css()

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
init_session_state()

# Visualizerã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
viz = Visualizer()


def load_sample_data(dataset_name: str) -> pd.DataFrame:
    """ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰"""
    
    if dataset_name == "california":
        from sklearn.datasets import fetch_california_housing
        data = fetch_california_housing()
        df = pd.DataFrame(data.data, columns=data.feature_names)
        df['MedHouseVal'] = data.target
        
        column_mapping = {
            'MedInc': 'ä¸–å¸¯åå…¥ä¸­å¤®å€¤',
            'HouseAge': 'ç¯‰å¹´æ•°',
            'AveRooms': 'å¹³å‡éƒ¨å±‹æ•°',
            'AveBedrms': 'å¹³å‡å¯å®¤æ•°',
            'Population': 'äººå£',
            'AveOccup': 'å¹³å‡ä¸–å¸¯äººæ•°',
            'Latitude': 'ç·¯åº¦',
            'Longitude': 'çµŒåº¦',
            'MedHouseVal': 'ä½å®…ä¾¡æ ¼'
        }
        df = df.rename(columns=column_mapping)
        return df
    
    elif dataset_name == "tokyo_sample":
        np.random.seed(42)
        n_samples = 1000
        
        districts = ['æ¸¯åŒº', 'æ¸‹è°·åŒº', 'æ–°å®¿åŒº', 'ä¸–ç”°è°·åŒº', 'ç›®é»’åŒº', 
                    'å“å·åŒº', 'å¤§ç”°åŒº', 'æ‰ä¸¦åŒº', 'ä¸­é‡åŒº', 'ç·´é¦¬åŒº']
        
        df = pd.DataFrame({
            'åŒº': np.random.choice(districts, n_samples),
            'ç¯‰å¹´æ•°': np.random.randint(0, 50, n_samples),
            'é¢ç©_m2': np.random.uniform(20, 150, n_samples).round(1),
            'éšæ•°': np.random.randint(1, 50, n_samples),
            'é§…å¾’æ­©åˆ†': np.random.randint(1, 20, n_samples),
            'éƒ¨å±‹æ•°': np.random.randint(1, 5, n_samples),
            'ãƒãƒ«ã‚³ãƒ‹ãƒ¼æœ‰': np.random.choice([0, 1], n_samples),
            'ã‚ªãƒ¼ãƒˆãƒ­ãƒƒã‚¯': np.random.choice([0, 1], n_samples),
        })
        
        base_price = 3000
        district_premium = {'æ¸¯åŒº': 2000, 'æ¸‹è°·åŒº': 1800, 'æ–°å®¿åŒº': 1500, 
                          'ä¸–ç”°è°·åŒº': 1200, 'ç›®é»’åŒº': 1400, 'å“å·åŒº': 1100,
                          'å¤§ç”°åŒº': 800, 'æ‰ä¸¦åŒº': 900, 'ä¸­é‡åŒº': 850, 'ç·´é¦¬åŒº': 700}
        
        df['ä¾¡æ ¼_ä¸‡å††'] = (
            base_price +
            df['åŒº'].map(district_premium) +
            df['é¢ç©_m2'] * 50 -
            df['ç¯‰å¹´æ•°'] * 30 +
            df['éšæ•°'] * 20 -
            df['é§…å¾’æ­©åˆ†'] * 50 +
            df['éƒ¨å±‹æ•°'] * 200 +
            df['ãƒãƒ«ã‚³ãƒ‹ãƒ¼æœ‰'] * 100 +
            df['ã‚ªãƒ¼ãƒˆãƒ­ãƒƒã‚¯'] * 150 +
            np.random.normal(0, 500, n_samples)
        ).round(0).astype(int)
        
        df['ä¾¡æ ¼_ä¸‡å††'] = df['ä¾¡æ ¼_ä¸‡å††'].clip(lower=1000)
        return df
    
    elif dataset_name == "boston_simple":
        np.random.seed(42)
        n_samples = 500
        
        df = pd.DataFrame({
            'RM': np.random.uniform(4, 9, n_samples).round(2),
            'LSTAT': np.random.uniform(2, 35, n_samples).round(2),
            'PTRATIO': np.random.uniform(12, 22, n_samples).round(1),
            'DIS': np.random.uniform(1, 12, n_samples).round(2),
            'NOX': np.random.uniform(0.4, 0.9, n_samples).round(3),
            'AGE': np.random.uniform(10, 100, n_samples).round(1),
            'TAX': np.random.randint(180, 720, n_samples),
            'CRIM': np.random.exponential(3, n_samples).round(3),
        })
        
        df['PRICE'] = (
            50 +
            df['RM'] * 5 -
            df['LSTAT'] * 0.5 -
            df['PTRATIO'] * 0.8 +
            df['DIS'] * 0.3 -
            df['NOX'] * 15 -
            df['AGE'] * 0.05 -
            df['TAX'] * 0.02 -
            df['CRIM'] * 0.3 +
            np.random.normal(0, 3, n_samples)
        ).round(1).clip(lower=5)
        
        column_mapping = {
            'RM': 'éƒ¨å±‹æ•°',
            'LSTAT': 'ä½æ‰€å¾—è€…ç‡',
            'PTRATIO': 'ç”Ÿå¾’æ•™å¸«æ¯”ç‡',
            'DIS': 'éƒ½å¿ƒè·é›¢',
            'NOX': 'å¤§æ°—æ±šæŸ“æŒ‡æ•°',
            'AGE': 'ç¯‰å¹´æ•°',
            'TAX': 'å›ºå®šè³‡ç”£ç¨',
            'CRIM': 'çŠ¯ç½ªç‡',
            'PRICE': 'ä½å®…ä¾¡æ ¼'
        }
        df = df.rename(columns=column_mapping)
        return df
    
    return None


def create_prediction_form(feature_columns: list, df_original: pd.DataFrame, key_prefix: str = "input") -> dict:
    """äºˆæ¸¬ç”¨ã®å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ã‚’ä½œæˆ"""
    
    input_data = {}
    col1, col2 = st.columns(2)
    
    for i, col in enumerate(feature_columns):
        if col in df_original.columns:
            col_data = df_original[col]
            
            if col_data.dtype == 'object' or col_data.nunique() < 10:
                unique_values = col_data.unique().tolist()
                with col1 if i % 2 == 0 else col2:
                    input_data[col] = st.selectbox(
                        f"{col}",
                        options=unique_values,
                        key=f"{key_prefix}_{col}"
                    )
            else:
                min_val = float(col_data.min())
                max_val = float(col_data.max())
                mean_val = float(col_data.mean())
                
                with col1 if i % 2 == 0 else col2:
                    if col_data.dtype in ['int64', 'int32']:
                        input_data[col] = st.number_input(
                            f"{col}",
                            min_value=int(min_val),
                            max_value=int(max_val * 1.5),
                            value=int(mean_val),
                            step=1,
                            key=f"{key_prefix}_{col}"
                        )
                    else:
                        input_data[col] = st.number_input(
                            f"{col}",
                            min_value=min_val * 0.5,
                            max_value=max_val * 1.5,
                            value=mean_val,
                            step=(max_val - min_val) / 100,
                            format="%.2f",
                            key=f"{key_prefix}_{col}"
                        )
        else:
            with col1 if i % 2 == 0 else col2:
                input_data[col] = st.number_input(
                    f"{col}",
                    value=0.0,
                    key=f"{key_prefix}_{col}"
                )
    
    return input_data


def main():
    """ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³"""
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼ãƒãƒŠãƒ¼ç”»åƒ
    if os.path.exists("images/Appbanner.png"):
        st.image("images/Appbanner.png", use_container_width=True)
    else:
        create_header(
            "RealEstateMLStudio",
            "XGBoost / LightGBM / CatBoost / ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚° ã«ã‚ˆã‚‹é«˜ç²¾åº¦ä¸å‹•ç”£ä¾¡æ ¼äºˆæ¸¬"
        )
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    with st.sidebar:
        st.image("https://img.icons8.com/3d-fluency/94/home.png", width=80)
        st.title("è¨­å®šãƒ‘ãƒãƒ«")
        
        st.markdown("---")
        
        # ãƒ¢ãƒ‡ãƒ«é¸æŠ
        st.subheader("ğŸ¤– ãƒ¢ãƒ‡ãƒ«è¨­å®š")
        model_type = st.selectbox(
            "ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ é¸æŠ",
            ["XGBoost", "LightGBM", "CatBoost", "ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚° (ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«)", "å…¨ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ"],
            help="ä½¿ç”¨ã™ã‚‹æ©Ÿæ¢°å­¦ç¿’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’é¸æŠ"
        )
        
        if model_type == "ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚° (ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«)":
            st.markdown("**ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°æ§‹æˆ**")
            use_xgb_stack = st.checkbox("XGBoost", value=True)
            use_lgb_stack = st.checkbox("LightGBM", value=True)
            use_cat_stack = st.checkbox("CatBoost", value=True)
        else:
            use_xgb_stack = use_lgb_stack = use_cat_stack = True
        
        include_stacking = False
        if model_type == "å…¨ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ":
            include_stacking = st.checkbox("ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°ã‚‚å«ã‚ã‚‹", value=False)
        
        st.subheader("âš™ï¸ ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°è¨­å®š")
        use_tuning = st.checkbox("ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°", value=False)
        
        if use_tuning:
            n_trials = st.slider("è©¦è¡Œå›æ•°", 10, 200, 50, 10)
        else:
            n_trials = 0
        
        use_cv = st.checkbox("äº¤å·®æ¤œè¨¼ã‚’å®Ÿè¡Œ", value=True)
        if use_cv:
            cv_folds = st.slider("Foldæ•°", 3, 10, 5)
        else:
            cv_folds = 5
        
        st.subheader("ğŸ”§ å‰å‡¦ç†è¨­å®š")
        handle_missing = st.checkbox("æ¬ æå€¤ã‚’è‡ªå‹•å‡¦ç†", value=True)
        encode_categorical = st.checkbox("ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰", value=True)
        handle_outliers = st.checkbox("ç•°å¸¸å€¤ã‚’å‡¦ç†", value=False)
        scale_features = st.checkbox("ç‰¹å¾´é‡ã‚’ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°", value=False)
        
        if model_type == "CatBoost":
            st.subheader("ğŸ± CatBoostè¨­å®š")
            use_native_cat = st.checkbox(
                "ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã‚’ãƒã‚¤ãƒ†ã‚£ãƒ–å‡¦ç†", 
                value=True,
                help="CatBoostã®ãƒã‚¤ãƒ†ã‚£ãƒ–ã‚«ãƒ†ã‚´ãƒªå‡¦ç†ã‚’ä½¿ç”¨"
            )
            if use_native_cat:
                encode_categorical = False
        else:
            use_native_cat = False
        
        st.markdown("---")
        
        st.subheader("ğŸ’¾ ãƒ¢ãƒ‡ãƒ«ç®¡ç†")
        if st.session_state.get('is_trained', False):
            if st.button("ğŸ“¥ ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜"):
                save_model()
        
        uploaded_model = st.file_uploader("ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿", type=['joblib'])
        if uploaded_model:
            load_saved_model(uploaded_model)
    
    # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ - 6ã‚¿ãƒ–ã«æ‹¡å¼µ
    tabs = st.tabs([
        "ğŸ“¤ ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", 
        "ğŸ” ãƒ‡ãƒ¼ã‚¿åˆ†æ (EDA)", 
        "ğŸ¯ ãƒ¢ãƒ‡ãƒ«å­¦ç¿’",
        "ğŸ“Š è©•ä¾¡çµæœ",
        "ğŸ”® äºˆæ¸¬å®Ÿè¡Œ",
        "ğŸ”¬ è©³ç´°åˆ†æ"  # æ–°ã—ã„ã‚¿ãƒ–
    ])
    
    # ã‚¿ãƒ–1: ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    with tabs[0]:
        render_data_upload_tab()
    
    # ã‚¿ãƒ–2: ãƒ‡ãƒ¼ã‚¿åˆ†æ (EDA)
    with tabs[1]:
        render_eda_tab()
    
    # ã‚¿ãƒ–3: ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
    with tabs[2]:
        render_training_tab(model_type, use_tuning, n_trials, use_cv, cv_folds,
                           handle_missing, encode_categorical, handle_outliers,
                           scale_features, use_native_cat, use_xgb_stack,
                           use_lgb_stack, use_cat_stack, include_stacking)
    
    # ã‚¿ãƒ–4: è©•ä¾¡çµæœ
    with tabs[3]:
        render_evaluation_tab()
    
    # ã‚¿ãƒ–5: äºˆæ¸¬å®Ÿè¡Œ
    with tabs[4]:
        render_prediction_tab()
    
    # ã‚¿ãƒ–6: è©³ç´°åˆ†æï¼ˆæ–°æ©Ÿèƒ½ï¼‰
    with tabs[5]:
        render_advanced_analysis_tab()


def render_data_upload_tab():
    """ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¿ãƒ–"""
    st.header("Step 1: ãƒ‡ãƒ¼ã‚¿ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("""
        <div class="info-card">
            <strong>ğŸ“‹ å¯¾å¿œãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ</strong><br>
            CSVå½¢å¼ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‰ãƒ©ãƒƒã‚°ï¼†ãƒ‰ãƒ­ãƒƒãƒ—ã—ã¦ãã ã•ã„ã€‚<br>
            ãƒ»æ•™å¸«ã‚ã‚Šå­¦ç¿’ç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆç›®çš„å¤‰æ•°ã‚’å«ã‚€ï¼‰<br>
            ãƒ»æ¬ æå€¤ã‚„ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã¯è‡ªå‹•ã§å‡¦ç†ã•ã‚Œã¾ã™
        </div>
        """, unsafe_allow_html=True)
        
        uploaded_file = st.file_uploader(
            "å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
            type=['csv'],
            help="CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‰ãƒ©ãƒƒã‚°ï¼†ãƒ‰ãƒ­ãƒƒãƒ—"
        )
    
    with col2:
        st.markdown("""
        <div class="metric-card">
            <div style="font-size: 3rem;">ğŸ“Š</div>
            <div class="metric-label">ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦<br>åˆ†æã‚’é–‹å§‹ã—ã¾ã—ã‚‡ã†</div>
        </div>
        """, unsafe_allow_html=True)
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    st.markdown("---")
    st.subheader("ğŸ® ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã§è©¦ã™")
    st.markdown("ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯ã€ä»¥ä¸‹ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã‚¢ãƒ—ãƒªã®æ©Ÿèƒ½ã‚’è©¦ã™ã“ã¨ãŒã§ãã¾ã™ã€‚")
    
    sample_col1, sample_col2, sample_col3 = st.columns(3)
    
    with sample_col1:
        st.markdown("""
        **ğŸŒ´ ã‚«ãƒªãƒ•ã‚©ãƒ«ãƒ‹ã‚¢ä½å®…**
        - 20,640ä»¶ã®ãƒ‡ãƒ¼ã‚¿
        - 8ã¤ã®ç‰¹å¾´é‡
        - ä½å®…ä¾¡æ ¼ï¼ˆä¸­å¤®å€¤ï¼‰ã‚’äºˆæ¸¬
        """)
        if st.button("ğŸ“¥ ã‚«ãƒªãƒ•ã‚©ãƒ«ãƒ‹ã‚¢ä½å®…ãƒ‡ãƒ¼ã‚¿", key="load_california"):
            df = load_sample_data("california")
            st.session_state['df'] = df
            st.session_state['sample_data_name'] = 'ã‚«ãƒªãƒ•ã‚©ãƒ«ãƒ‹ã‚¢ä½å®…'
            st.rerun()
    
    with sample_col2:
        st.markdown("""
        **ğŸ—¼ æ±äº¬ãƒãƒ³ã‚·ãƒ§ãƒ³ï¼ˆæ¶ç©ºï¼‰**
        - 1,000ä»¶ã®ãƒ‡ãƒ¼ã‚¿
        - åŒºãƒ»é¢ç©ãƒ»ç¯‰å¹´æ•°ãªã©
        - ãƒãƒ³ã‚·ãƒ§ãƒ³ä¾¡æ ¼ã‚’äºˆæ¸¬
        """)
        if st.button("ğŸ“¥ æ±äº¬ãƒãƒ³ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿", key="load_tokyo"):
            df = load_sample_data("tokyo_sample")
            st.session_state['df'] = df
            st.session_state['sample_data_name'] = 'æ±äº¬ãƒãƒ³ã‚·ãƒ§ãƒ³'
            st.rerun()
    
    with sample_col3:
        st.markdown("""
        **ğŸ˜ï¸ ã‚·ãƒ³ãƒ—ãƒ«ä½å®…ãƒ‡ãƒ¼ã‚¿**
        - 500ä»¶ã®ãƒ‡ãƒ¼ã‚¿
        - éƒ¨å±‹æ•°ãƒ»ç¯‰å¹´æ•°ãªã©
        - ä½å®…ä¾¡æ ¼ã‚’äºˆæ¸¬
        """)
        if st.button("ğŸ“¥ ã‚·ãƒ³ãƒ—ãƒ«ä½å®…ãƒ‡ãƒ¼ã‚¿", key="load_boston"):
            df = load_sample_data("boston_simple")
            st.session_state['df'] = df
            st.session_state['sample_data_name'] = 'ã‚·ãƒ³ãƒ—ãƒ«ä½å®…'
            st.rerun()
    
    if uploaded_file:
        df = pd.read_csv(uploaded_file)
        st.session_state['df'] = df
        st.session_state['sample_data_name'] = None
    
    if st.session_state.get('df') is not None:
        df = st.session_state['df']
        
        if st.session_state.get('sample_data_name'):
            show_success_message(f"ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã€Œ{st.session_state['sample_data_name']}ã€ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {len(df):,}è¡Œ Ã— {len(df.columns)}åˆ—")
        else:
            show_success_message(f"ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {len(df):,}è¡Œ Ã— {len(df.columns)}åˆ—")
        
        display_dataframe_info(df)
        
        st.markdown("---")
        st.subheader("ğŸ“‹ ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
        st.dataframe(df.head(20), use_container_width=True, height=400)
        
        col1, col2 = st.columns(2)
        with col1:
            st.subheader("ğŸ”¢ æ•°å€¤åˆ—")
            numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
            st.write(numeric_cols)
        with col2:
            st.subheader("ğŸ“ ã‚«ãƒ†ã‚´ãƒªåˆ—")
            cat_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()
            st.write(cat_cols if cat_cols else "ãªã—")


def render_eda_tab():
    """EDAã‚¿ãƒ–"""
    st.header("Step 2: æ¢ç´¢çš„ãƒ‡ãƒ¼ã‚¿åˆ†æ (EDA)")
    
    if st.session_state.get('df') is not None:
        df = st.session_state['df']
        
        st.subheader("ğŸ“ˆ åŸºæœ¬çµ±è¨ˆé‡")
        st.dataframe(df.describe(), use_container_width=True)
        
        st.subheader("ğŸ” æ¬ æå€¤åˆ†æ")
        missing = df.isnull().sum()
        missing_pct = (missing / len(df) * 100).round(2)
        missing_df = pd.DataFrame({
            'æ¬ ææ•°': missing,
            'æ¬ æç‡ (%)': missing_pct
        }).sort_values('æ¬ ææ•°', ascending=False)
        
        col1, col2 = st.columns([1, 2])
        with col1:
            st.dataframe(missing_df[missing_df['æ¬ ææ•°'] > 0], use_container_width=True)
        with col2:
            if missing.sum() > 0:
                fig = viz.plot_feature_importance(
                    missing[missing > 0].sort_values(ascending=False),
                    top_n=20,
                    title="æ¬ æå€¤ã®åˆ†å¸ƒ"
                )
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.success("âœ… æ¬ æå€¤ã¯ã‚ã‚Šã¾ã›ã‚“")
        
        st.subheader("ğŸ”— ç‰¹å¾´é‡ç›¸é–¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹")
        fig_corr = viz.plot_eda_dashboard(df)
        if fig_corr:
            st.plotly_chart(fig_corr, use_container_width=True)
        
        st.subheader("ğŸ“Š æ•°å€¤å¤‰æ•°ã®åˆ†å¸ƒ")
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        
        if numeric_cols:
            selected_col = st.selectbox("è¡¨ç¤ºã™ã‚‹åˆ—ã‚’é¸æŠ", numeric_cols)
            
            import plotly.express as px
            fig = px.histogram(
                df, x=selected_col, 
                nbins=50,
                title=f"{selected_col} ã®åˆ†å¸ƒ",
                marginal="box"
            )
            fig.update_layout(template='plotly_white')
            st.plotly_chart(fig, use_container_width=True)
    else:
        show_warning_message("å…ˆã«ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")


def render_training_tab(model_type, use_tuning, n_trials, use_cv, cv_folds,
                        handle_missing, encode_categorical, handle_outliers,
                        scale_features, use_native_cat, use_xgb_stack,
                        use_lgb_stack, use_cat_stack, include_stacking):
    """ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã‚¿ãƒ–"""
    st.header("Step 3: ãƒ¢ãƒ‡ãƒ«å­¦ç¿’")
    
    if st.session_state.get('df') is not None:
        df = st.session_state['df']
        
        col1, col2 = st.columns(2)
        
        with col1:
            target_column = st.selectbox(
                "ğŸ¯ ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ—ï¼ˆäºˆæ¸¬ã—ãŸã„åˆ—ï¼‰",
                df.columns.tolist(),
                index=len(df.columns) - 1
            )
            st.session_state['target_column'] = target_column
        
        with col2:
            test_size = st.slider("ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®å‰²åˆ", 0.1, 0.4, 0.2, 0.05)
        
        st.markdown("---")
        
        model_info = {
            "XGBoost": "ğŸš€ é«˜ç²¾åº¦ãªå‹¾é…ãƒ–ãƒ¼ã‚¹ãƒ†ã‚£ãƒ³ã‚°ã€‚ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸæ€§èƒ½ã€‚",
            "LightGBM": "âš¡ é«˜é€Ÿãƒ»è»½é‡ã€‚å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã«æœ€é©ã€‚",
            "CatBoost": "ğŸ± ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã«å¼·ã„ã€‚éå­¦ç¿’ã—ã«ãã„ã€‚",
            "ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚° (ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«)": "ğŸ† è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã‚’çµ„ã¿åˆã‚ã›æœ€é«˜ç²¾åº¦ã‚’å®Ÿç¾ã€‚",
            "å…¨ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ": "ğŸ“Š å…¨ãƒ¢ãƒ‡ãƒ«ã‚’æ¯”è¼ƒã—ã¦æœ€é©ãªã‚‚ã®ã‚’é¸æŠã€‚"
        }
        
        st.info(f"**é¸æŠä¸­ã®ãƒ¢ãƒ‡ãƒ«**: {model_type}\n\n{model_info[model_type]}")
        
        st.markdown("---")
        st.subheader("ğŸ”§ ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†")
        
        if st.button("å‰å‡¦ç†ã‚’å®Ÿè¡Œ", key="preprocess_btn"):
            with st.spinner("å‰å‡¦ç†ä¸­..."):
                preprocessor = DataPreprocessor()
                
                actual_encode = encode_categorical and not (model_type == "CatBoost" and use_native_cat)
                
                df_processed = preprocessor.auto_preprocess(
                    df,
                    target_column=target_column,
                    handle_missing=handle_missing,
                    encode_cat=actual_encode,
                    handle_outliers_flag=handle_outliers,
                    scale=scale_features
                )
                
                st.session_state['df_processed'] = df_processed
                st.session_state['preprocessor'] = preprocessor
                st.session_state['df_original'] = df.copy()
                st.session_state['use_native_cat'] = use_native_cat if model_type == "CatBoost" else False
                
                show_success_message("å‰å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                
                st.write("å‰å‡¦ç†å¾Œã®ãƒ‡ãƒ¼ã‚¿:")
                display_dataframe_info(df_processed)
                st.dataframe(df_processed.head(10), use_container_width=True)
        
        st.markdown("---")
        st.subheader("ğŸš€ ãƒ¢ãƒ‡ãƒ«å­¦ç¿’")
        
        if st.session_state.get('df_processed') is not None:
            if st.button("ğŸ“ å­¦ç¿’é–‹å§‹", type="primary", key="train_btn"):
                train_model(
                    model_type, 
                    use_tuning, 
                    n_trials, 
                    use_cv, 
                    cv_folds, 
                    test_size,
                    use_xgb_stack,
                    use_lgb_stack,
                    use_cat_stack,
                    include_stacking
                )
        else:
            st.info("ğŸ‘† ã¾ãšå‰å‡¦ç†ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
    else:
        show_warning_message("å…ˆã«ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")


def render_evaluation_tab():
    """è©•ä¾¡çµæœã‚¿ãƒ–"""
    st.header("Step 4: ãƒ¢ãƒ‡ãƒ«è©•ä¾¡")
    
    if st.session_state.get('is_trained', False):
        trainer = st.session_state['trainer']
        metrics = st.session_state['metrics']
        
        # è©•ä¾¡æŒ‡æ¨™ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ï¼ˆå¸¸ã«è¡¨ç¤ºå¯èƒ½ï¼‰
        st.subheader("ğŸ“Š è©•ä¾¡æŒ‡æ¨™ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
        fig_metrics = viz.plot_metrics_dashboard(metrics, getattr(trainer, 'cv_scores', None))
        st.plotly_chart(fig_metrics, use_container_width=True)
        
        # y_testã¨y_predãŒã‚ã‚‹å ´åˆã®ã¿è©³ç´°ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤º
        y_test = getattr(trainer, 'y_test', None)
        y_pred = getattr(trainer, 'y_pred', None)
        
        if y_test is not None and y_pred is not None:
            y_test_vals = y_test.values if hasattr(y_test, 'values') else y_test
            
            st.subheader("ğŸ¯ å®Ÿæ¸¬å€¤ vs äºˆæ¸¬å€¤")
            fig_pred = viz.plot_actual_vs_predicted(y_test_vals, y_pred)
            st.plotly_chart(fig_pred, use_container_width=True)
            
            st.subheader("ğŸ“ˆ æ®‹å·®åˆ†æ")
            fig_residuals = viz.plot_residuals(y_test_vals, y_pred)
            st.plotly_chart(fig_residuals, use_container_width=True)
            
            st.subheader("ğŸ“Š äºˆæ¸¬å€¤ã¨å®Ÿæ¸¬å€¤ã®åˆ†å¸ƒ")
            fig_dist = viz.plot_prediction_distribution(y_test_vals, y_pred)
            st.plotly_chart(fig_dist, use_container_width=True)
        else:
            st.info("ğŸ“ èª­ã¿è¾¼ã‚“ã ãƒ¢ãƒ‡ãƒ«ã®ãŸã‚ã€è©³ç´°ãªè©•ä¾¡ã‚°ãƒ©ãƒ•ã¯è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã§äºˆæ¸¬ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        
        # ç‰¹å¾´é‡é‡è¦åº¦
        feature_importance = getattr(trainer, 'feature_importance', None)
        if feature_importance is not None:
            st.subheader("ğŸ”‘ ç‰¹å¾´é‡é‡è¦åº¦")
            fig_importance = viz.plot_feature_importance(
                feature_importance,
                top_n=min(20, len(feature_importance))
            )
            st.plotly_chart(fig_importance, use_container_width=True)
        
        # äº¤å·®æ¤œè¨¼çµæœ
        cv_scores = getattr(trainer, 'cv_scores', None)
        if cv_scores:
            st.subheader("ğŸ”„ äº¤å·®æ¤œè¨¼çµæœ")
            fig_cv = viz.plot_cv_results(cv_scores)
            st.plotly_chart(fig_cv, use_container_width=True)
        
        # ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒçµæœ
        if st.session_state.get('comparison_results'):
            st.subheader("âš–ï¸ ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ")
            comparison = st.session_state['comparison_results']
            fig_compare = viz.plot_model_comparison(comparison['comparison_df'])
            st.plotly_chart(fig_compare, use_container_width=True)
            
            st.dataframe(comparison['comparison_df'], use_container_width=True)
            
            best = get_best_model(comparison)
            st.success(f"ğŸ† æœ€è‰¯ãƒ¢ãƒ‡ãƒ«: **{best.upper()}** (RÂ² = {comparison[best]['metrics']['r2']:.4f})")
        
    else:
        show_warning_message("å…ˆã«ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã—ã¦ãã ã•ã„")


def render_prediction_tab():
    """äºˆæ¸¬å®Ÿè¡Œã‚¿ãƒ–"""
    st.header("Step 5: æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã§äºˆæ¸¬")
    
    if st.session_state.get('is_trained', False):
        
        pred_method = st.radio(
            "äºˆæ¸¬æ–¹æ³•ã‚’é¸æŠ",
            ["ğŸ“ CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ä¸€æ‹¬äºˆæ¸¬", "ğŸ“ æ‰‹å…¥åŠ›ã§äºˆæ¸¬"],
            horizontal=True
        )
        
        st.markdown("---")
        
        if pred_method == "ğŸ“ CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ä¸€æ‹¬äºˆæ¸¬":
            st.markdown("""
            <div class="info-card">
                <strong>ğŸ“‹ äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™</strong><br>
                å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨åŒã˜å½¢å¼ï¼ˆåŒã˜åˆ—åãƒ»é †åºï¼‰ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚
            </div>
            """, unsafe_allow_html=True)
            
            pred_file = st.file_uploader(
                "äºˆæ¸¬ã—ãŸã„ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
                type=['csv'],
                key="pred_uploader"
            )
            
            if pred_file:
                df_pred = pd.read_csv(pred_file)
                
                st.subheader("ğŸ“‹ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿")
                st.dataframe(df_pred.head(10), use_container_width=True)
                
                if st.button("ğŸ”® äºˆæ¸¬å®Ÿè¡Œ", type="primary", key="batch_predict"):
                    with st.spinner("äºˆæ¸¬ä¸­..."):
                        try:
                            preprocessor = st.session_state.get('preprocessor')
                            if preprocessor and not st.session_state.get('use_native_cat', False):
                                df_pred_processed = preprocessor.transform_new_data(df_pred)
                            else:
                                df_pred_processed = df_pred
                            
                            trainer = st.session_state['trainer']
                            predictions = trainer.predict(df_pred_processed)
                            
                            df_result = df_pred.copy()
                            df_result['äºˆæ¸¬å€¤'] = predictions
                            
                            show_success_message("äºˆæ¸¬ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                            
                            st.subheader("ğŸ“Š äºˆæ¸¬çµæœ")
                            st.dataframe(df_result, use_container_width=True, height=400)
                            
                            col1, col2, col3, col4 = st.columns(4)
                            with col1:
                                st.metric("å¹³å‡äºˆæ¸¬å€¤", f"{predictions.mean():,.2f}")
                            with col2:
                                st.metric("æœ€å°äºˆæ¸¬å€¤", f"{predictions.min():,.2f}")
                            with col3:
                                st.metric("æœ€å¤§äºˆæ¸¬å€¤", f"{predictions.max():,.2f}")
                            with col4:
                                st.metric("æ¨™æº–åå·®", f"{predictions.std():,.2f}")
                            
                            csv = df_result.to_csv(index=False).encode('utf-8-sig')
                            st.download_button(
                                "ğŸ“¥ äºˆæ¸¬çµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                                csv,
                                "prediction_results.csv",
                                "text/csv"
                            )
                            
                        except Exception as e:
                            st.error(f"äºˆæ¸¬ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        
        else:
            st.markdown("""
            <div class="info-card">
                <strong>ğŸ“ æ‰‹å…¥åŠ›ã§äºˆæ¸¬</strong><br>
                ç‰©ä»¶æƒ…å ±ã‚’å…¥åŠ›ã—ã¦ã€ä¾¡æ ¼ã‚’äºˆæ¸¬ã—ã¾ã™ã€‚
            </div>
            """, unsafe_allow_html=True)
            
            feature_columns = st.session_state.get('feature_columns', [])
            df_original = st.session_state.get('df_original', st.session_state.get('df'))
            
            if feature_columns and df_original is not None:
                st.subheader("ğŸ“ ç‰©ä»¶æƒ…å ±ã‚’å…¥åŠ›")
                input_data = create_prediction_form(feature_columns, df_original, "pred")
                
                st.markdown("---")
                
                if st.button("ğŸ”® ã“ã®ç‰©ä»¶ã®ä¾¡æ ¼ã‚’äºˆæ¸¬", type="primary", key="single_predict"):
                    with st.spinner("äºˆæ¸¬ä¸­..."):
                        try:
                            df_input = pd.DataFrame([input_data])
                            
                            preprocessor = st.session_state.get('preprocessor')
                            if preprocessor and not st.session_state.get('use_native_cat', False):
                                df_input_processed = preprocessor.transform_new_data(df_input)
                            else:
                                df_input_processed = df_input
                            
                            if not st.session_state.get('use_native_cat', False):
                                df_input_processed = df_input_processed.select_dtypes(include=[np.number])
                            
                            trainer = st.session_state['trainer']
                            prediction = trainer.predict(df_input_processed)[0]
                            
                            st.markdown("---")
                            st.subheader("ğŸ‰ äºˆæ¸¬çµæœ")
                            
                            target_column = st.session_state.get('target_column', 'ä¾¡æ ¼')
                            
                            st.markdown(f"""
                            <div style="
                                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                                border-radius: 20px;
                                padding: 40px;
                                text-align: center;
                                color: white;
                                margin: 20px 0;
                                box-shadow: 0 10px 30px rgba(0,0,0,0.2);
                            ">
                                <h2 style="margin: 0; font-size: 1.2rem; opacity: 0.9;">äºˆæ¸¬ {target_column}</h2>
                                <h1 style="margin: 10px 0; font-size: 3.5rem; font-weight: bold;">
                                    {prediction:,.2f}
                                </h1>
                            </div>
                            """, unsafe_allow_html=True)
                            
                            st.subheader("ğŸ“‹ å…¥åŠ›æ¡ä»¶")
                            col1, col2 = st.columns(2)
                            items = list(input_data.items())
                            mid = len(items) // 2
                            
                            with col1:
                                for key, value in items[:mid]:
                                    st.write(f"**{key}**: {value}")
                            with col2:
                                for key, value in items[mid:]:
                                    st.write(f"**{key}**: {value}")
                            
                        except Exception as e:
                            st.error(f"äºˆæ¸¬ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            else:
                st.warning("ç‰¹å¾´é‡æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ¢ãƒ‡ãƒ«ã‚’å†å­¦ç¿’ã—ã¦ãã ã•ã„ã€‚")
    else:
        show_warning_message("å…ˆã«ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã—ã¦ãã ã•ã„")


def render_advanced_analysis_tab():
    """è©³ç´°åˆ†æã‚¿ãƒ–ï¼ˆSHAP, ä¿¡é ¼åŒºé–“, PDF, What-ifï¼‰"""
    st.header("Step 6: è©³ç´°åˆ†æ")
    
    if not st.session_state.get('is_trained', False):
        show_warning_message("å…ˆã«ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã—ã¦ãã ã•ã„")
        return
    
    # ã‚µãƒ–ã‚¿ãƒ–ã‚’ä½œæˆ
    analysis_tabs = st.tabs([
        "ğŸ” SHAPåˆ†æ",
        "ğŸ“Š äºˆæ¸¬ä¿¡é ¼åŒºé–“",
        "ğŸ“„ PDFãƒ¬ãƒãƒ¼ãƒˆ",
        "ğŸ”„ What-ifåˆ†æ"
    ])
    
    trainer = st.session_state['trainer']
    feature_columns = st.session_state.get('feature_columns', [])
    df_original = st.session_state.get('df_original', st.session_state.get('df'))
    df_processed = st.session_state.get('df_processed')
    target_column = st.session_state.get('target_column', 'ä¾¡æ ¼')
    
    # SHAPåˆ†æã‚¿ãƒ–
    with analysis_tabs[0]:
        st.subheader("ğŸ” SHAPåˆ†æ - äºˆæ¸¬ã®èª¬æ˜")
        st.markdown("""
        SHAPï¼ˆSHapley Additive exPlanationsï¼‰ã¯ã€å„ç‰¹å¾´é‡ãŒäºˆæ¸¬ã«ã©ã‚Œã ã‘è²¢çŒ®ã—ã¦ã„ã‚‹ã‹ã‚’èª¬æ˜ã—ã¾ã™ã€‚
        - **æ­£ã®SHAPå€¤**: äºˆæ¸¬ä¾¡æ ¼ã‚’ä¸Šã’ã‚‹è¦å› 
        - **è² ã®SHAPå€¤**: äºˆæ¸¬ä¾¡æ ¼ã‚’ä¸‹ã’ã‚‹è¦å› 
        """)
        
        if st.button("ğŸ”¬ SHAPåˆ†æã‚’å®Ÿè¡Œ", key="run_shap"):
            with st.spinner("SHAPå€¤ã‚’è¨ˆç®—ä¸­...ï¼ˆå°‘ã—æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ï¼‰"):
                try:
                    # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                    X_train = df_processed.drop(columns=[target_column])
                    if not st.session_state.get('use_native_cat', False):
                        X_train = X_train.select_dtypes(include=[np.number])
                    
                    # SHAPåˆ†æå™¨ã‚’ä½œæˆ
                    shap_analyzer = SHAPAnalyzer(trainer.model, X_train)
                    shap_analyzer.calculate_shap_values(max_samples=300)
                    
                    st.session_state['shap_analyzer'] = shap_analyzer
                    
                    # SHAPé‡è¦åº¦ãƒ—ãƒ­ãƒƒãƒˆ
                    st.subheader("ğŸ“Š SHAPç‰¹å¾´é‡é‡è¦åº¦")
                    fig_shap = shap_analyzer.plot_summary(top_n=15)
                    st.plotly_chart(fig_shap, use_container_width=True)
                    
                    show_success_message("SHAPåˆ†æãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                    
                except Exception as e:
                    st.error(f"SHAPåˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        
        # å€‹åˆ¥äºˆæ¸¬ã®èª¬æ˜
        if st.session_state.get('shap_analyzer'):
            st.markdown("---")
            st.subheader("ğŸ¯ å€‹åˆ¥äºˆæ¸¬ã®èª¬æ˜")
            st.markdown("ç‰©ä»¶æƒ…å ±ã‚’å…¥åŠ›ã—ã¦ã€äºˆæ¸¬ã®å†…è¨³ã‚’ç¢ºèªã§ãã¾ã™ã€‚")
            
            if feature_columns and df_original is not None:
                input_data_shap = create_prediction_form(feature_columns, df_original, "shap")
                
                if st.button("ğŸ“Š ã“ã®ç‰©ä»¶ã®äºˆæ¸¬ã‚’èª¬æ˜", key="explain_shap"):
                    with st.spinner("èª¬æ˜ã‚’ç”Ÿæˆä¸­..."):
                        try:
                            df_input = pd.DataFrame([input_data_shap])
                            
                            preprocessor = st.session_state.get('preprocessor')
                            if preprocessor and not st.session_state.get('use_native_cat', False):
                                df_input_processed = preprocessor.transform_new_data(df_input)
                            else:
                                df_input_processed = df_input
                            
                            if not st.session_state.get('use_native_cat', False):
                                df_input_processed = df_input_processed.select_dtypes(include=[np.number])
                            
                            shap_analyzer = st.session_state['shap_analyzer']
                            explanation = shap_analyzer.explain_prediction(df_input_processed)
                            
                            st.session_state['last_shap_explanation'] = explanation
                            st.session_state['last_input_data'] = df_input_processed
                            
                            # äºˆæ¸¬çµæœ
                            st.markdown(f"""
                            <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                                border-radius: 15px; padding: 20px; text-align: center; color: white; margin: 15px 0;">
                                <h3 style="margin: 0;">äºˆæ¸¬ {target_column}: {explanation['prediction']:,.2f}</h3>
                                <p style="margin: 5px 0; opacity: 0.8;">åŸºæº–å€¤: {explanation['base_value']:,.2f}</p>
                            </div>
                            """, unsafe_allow_html=True)
                            
                            # Force Plot
                            fig_force = shap_analyzer.plot_force_single(explanation)
                            st.plotly_chart(fig_force, use_container_width=True)
                            
                            # è²¢çŒ®åº¦ãƒ†ãƒ¼ãƒ–ãƒ«
                            st.subheader("ğŸ“‹ å…¨ç‰¹å¾´é‡ã®è²¢çŒ®åº¦")
                            st.dataframe(explanation['contributions'], use_container_width=True)
                            
                        except Exception as e:
                            st.error(f"èª¬æ˜ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
    
    # äºˆæ¸¬ä¿¡é ¼åŒºé–“ã‚¿ãƒ–
    with analysis_tabs[1]:
        st.subheader("ğŸ“Š äºˆæ¸¬ä¿¡é ¼åŒºé–“")
        st.markdown("""
        äºˆæ¸¬ã®ä¸ç¢ºå®Ÿæ€§ã‚’è€ƒæ…®ã—ãŸä¿¡é ¼åŒºé–“ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚
        - **50%ä¿¡é ¼åŒºé–“**: äºˆæ¸¬å€¤ã®50%ãŒã“ã®ç¯„å›²ã«å…¥ã‚‹
        - **80%ä¿¡é ¼åŒºé–“**: äºˆæ¸¬å€¤ã®80%ãŒã“ã®ç¯„å›²ã«å…¥ã‚‹
        - **95%ä¿¡é ¼åŒºé–“**: äºˆæ¸¬å€¤ã®95%ãŒã“ã®ç¯„å›²ã«å…¥ã‚‹
        """)
        
        if feature_columns and df_original is not None:
            st.subheader("ğŸ“ ç‰©ä»¶æƒ…å ±ã‚’å…¥åŠ›")
            input_data_interval = create_prediction_form(feature_columns, df_original, "interval")
            
            if st.button("ğŸ“ˆ ä¿¡é ¼åŒºé–“ä»˜ãã§äºˆæ¸¬", key="predict_interval"):
                with st.spinner("ä¿¡é ¼åŒºé–“ã‚’è¨ˆç®—ä¸­..."):
                    try:
                        df_input = pd.DataFrame([input_data_interval])
                        
                        preprocessor = st.session_state.get('preprocessor')
                        if preprocessor and not st.session_state.get('use_native_cat', False):
                            df_input_processed = preprocessor.transform_new_data(df_input)
                        else:
                            df_input_processed = df_input
                        
                        if not st.session_state.get('use_native_cat', False):
                            df_input_processed = df_input_processed.select_dtypes(include=[np.number])
                        
                        # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                        X_train = df_processed.drop(columns=[target_column])
                        y_train = df_processed[target_column]
                        if not st.session_state.get('use_native_cat', False):
                            X_train = X_train.select_dtypes(include=[np.number])
                        
                        # ä¿¡é ¼åŒºé–“è¨ˆç®—å™¨
                        interval_calc = PredictionInterval(trainer.model, X_train, y_train)
                        interval_calc.fit()
                        
                        result = interval_calc.predict_single_with_interval(df_input_processed)
                        
                        st.session_state['last_interval_result'] = result
                        st.session_state['last_input_data'] = df_input_processed
                        
                        # äºˆæ¸¬çµæœè¡¨ç¤º
                        prediction = result['prediction']
                        intervals = result['intervals']
                        
                        st.markdown(f"""
                        <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                            border-radius: 15px; padding: 25px; text-align: center; color: white; margin: 15px 0;">
                            <h2 style="margin: 0;">äºˆæ¸¬ {target_column}</h2>
                            <h1 style="margin: 10px 0; font-size: 3rem;">{prediction:,.2f}</h1>
                        </div>
                        """, unsafe_allow_html=True)
                        
                        # ä¿¡é ¼åŒºé–“è¡¨ç¤º
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric(
                                "50%ä¿¡é ¼åŒºé–“",
                                f"{intervals['50%']['lower']:,.1f} ã€œ {intervals['50%']['upper']:,.1f}"
                            )
                        with col2:
                            st.metric(
                                "80%ä¿¡é ¼åŒºé–“",
                                f"{intervals['80%']['lower']:,.1f} ã€œ {intervals['80%']['upper']:,.1f}"
                            )
                        with col3:
                            st.metric(
                                "95%ä¿¡é ¼åŒºé–“",
                                f"{intervals['95%']['lower']:,.1f} ã€œ {intervals['95%']['upper']:,.1f}"
                            )
                        
                        # ä¿¡é ¼åŒºé–“ãƒ—ãƒ­ãƒƒãƒˆ
                        fig_interval = interval_calc.plot_prediction_interval(result)
                        st.plotly_chart(fig_interval, use_container_width=True)
                        
                        show_success_message("ä¿¡é ¼åŒºé–“ã®è¨ˆç®—ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                        
                    except Exception as e:
                        st.error(f"ä¿¡é ¼åŒºé–“è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
    
    # PDFãƒ¬ãƒãƒ¼ãƒˆã‚¿ãƒ–
    with analysis_tabs[2]:
        st.subheader("ğŸ“„ PDFãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›")
        st.markdown("""
        äºˆæ¸¬çµæœã‚’PDFãƒ¬ãƒãƒ¼ãƒˆã¨ã—ã¦å‡ºåŠ›ã§ãã¾ã™ã€‚ãƒ¬ãƒãƒ¼ãƒˆã«ã¯ä»¥ä¸‹ãŒå«ã¾ã‚Œã¾ã™ï¼š
        - äºˆæ¸¬ä¾¡æ ¼ã‚µãƒãƒªãƒ¼
        - å…¥åŠ›ã—ãŸç‰©ä»¶æƒ…å ±
        - SHAPåˆ†æçµæœï¼ˆä¾¡æ ¼ç®—å‡ºæ ¹æ‹ ï¼‰
        - ä¿¡é ¼åŒºé–“
        - ãƒ¢ãƒ‡ãƒ«æ€§èƒ½æŒ‡æ¨™
        """)
        
        # äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹ã‹ç¢ºèª
        has_prediction = (st.session_state.get('last_shap_explanation') or 
                         st.session_state.get('last_interval_result'))
        
        if not has_prediction:
            st.info("ğŸ“ å…ˆã«ã€ŒSHAPåˆ†æã€ã¾ãŸã¯ã€Œäºˆæ¸¬ä¿¡é ¼åŒºé–“ã€ã‚¿ãƒ–ã§äºˆæ¸¬ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        else:
            st.success("âœ… äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã™ã€‚ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã§ãã¾ã™ã€‚")
            
            if st.button("ğŸ“„ PDFãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ", type="primary", key="generate_pdf"):
                with st.spinner("PDFã‚’ç”Ÿæˆä¸­..."):
                    try:
                        pdf_gen = PDFReportGenerator()
                        
                        # äºˆæ¸¬çµæœã‚’å–å¾—
                        shap_explanation = st.session_state.get('last_shap_explanation')
                        interval_result = st.session_state.get('last_interval_result')
                        input_data = st.session_state.get('last_input_data')
                        metrics = st.session_state.get('metrics')
                        
                        # äºˆæ¸¬å€¤ã‚’å–å¾—
                        if shap_explanation:
                            prediction_result = {'prediction': shap_explanation['prediction']}
                        elif interval_result:
                            prediction_result = {'prediction': interval_result['prediction']}
                        else:
                            prediction_result = {'prediction': 0}
                        
                        # PDFç”Ÿæˆ
                        pdf_bytes = pdf_gen.generate_report(
                            prediction_result=prediction_result,
                            shap_explanation=shap_explanation,
                            interval_result=interval_result,
                            model_metrics=metrics,
                            input_data=input_data,
                            target_column=target_column
                        )
                        
                        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
                        st.download_button(
                            label="ğŸ“¥ PDFã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                            data=pdf_bytes,
                            file_name=f"prediction_report_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.pdf",
                            mime="application/pdf"
                        )
                        
                        show_success_message("PDFãƒ¬ãƒãƒ¼ãƒˆãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸï¼")
                        
                    except Exception as e:
                        st.error(f"PDFç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
    
    # What-ifåˆ†æã‚¿ãƒ–
    with analysis_tabs[3]:
        st.subheader("ğŸ”„ What-ifåˆ†æï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰")
        st.markdown("""
        ç‰¹å¾´é‡ã®å€¤ã‚’å¤‰æ›´ã—ãŸå ´åˆã®äºˆæ¸¬ä¾¡æ ¼ã¸ã®å½±éŸ¿ã‚’åˆ†æã—ã¾ã™ã€‚
        - **æ„Ÿåº¦åˆ†æ**: 1ã¤ã®ç‰¹å¾´é‡ã‚’å¤‰åŒ–ã•ã›ãŸæ™‚ã®å½±éŸ¿
        - **ã‚·ãƒŠãƒªã‚ªæ¯”è¼ƒ**: è¤‡æ•°ã®æ¡ä»¶ã‚’çµ„ã¿åˆã‚ã›ãŸæ¯”è¼ƒ
        """)
        
        if feature_columns and df_original is not None:
            whatif_mode = st.radio(
                "åˆ†æãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠ",
                ["ğŸ“ˆ æ„Ÿåº¦åˆ†æï¼ˆ1å¤‰æ•°ï¼‰", "ğŸ“Š ã‚·ãƒŠãƒªã‚ªæ¯”è¼ƒï¼ˆè¤‡æ•°å¤‰æ•°ï¼‰"],
                horizontal=True
            )
            
            st.markdown("---")
            
            if whatif_mode == "ğŸ“ˆ æ„Ÿåº¦åˆ†æï¼ˆ1å¤‰æ•°ï¼‰":
                st.subheader("ğŸ“ ãƒ™ãƒ¼ã‚¹æ¡ä»¶ã‚’å…¥åŠ›")
                input_data_whatif = create_prediction_form(feature_columns, df_original, "whatif")
                
                st.markdown("---")
                
                # åˆ†æå¯¾è±¡ã®ç‰¹å¾´é‡ã‚’é¸æŠ
                numeric_features = [col for col in feature_columns 
                                   if df_original[col].dtype in ['int64', 'float64', 'int32', 'float32']]
                
                if numeric_features:
                    selected_feature = st.selectbox(
                        "ğŸ“Š åˆ†æã™ã‚‹ç‰¹å¾´é‡ã‚’é¸æŠ",
                        numeric_features
                    )
                    
                    if st.button("ğŸ”„ æ„Ÿåº¦åˆ†æã‚’å®Ÿè¡Œ", key="run_whatif"):
                        with st.spinner("åˆ†æä¸­..."):
                            try:
                                df_base = pd.DataFrame([input_data_whatif])
                                
                                preprocessor = st.session_state.get('preprocessor')
                                if preprocessor and not st.session_state.get('use_native_cat', False):
                                    df_base_processed = preprocessor.transform_new_data(df_base)
                                else:
                                    df_base_processed = df_base
                                
                                if not st.session_state.get('use_native_cat', False):
                                    df_base_processed = df_base_processed.select_dtypes(include=[np.number])
                                
                                # What-ifåˆ†æå™¨
                                X_original = df_original.drop(columns=[target_column], errors='ignore')
                                whatif = WhatIfAnalyzer(trainer.model, feature_columns, X_original)
                                
                                # æ„Ÿåº¦åˆ†æå®Ÿè¡Œ
                                sensitivity_df = whatif.analyze_feature_impact(
                                    df_base_processed, 
                                    selected_feature,
                                    n_points=20
                                )
                                
                                # çµæœè¡¨ç¤º
                                st.subheader(f"ğŸ“Š {selected_feature} ã®æ„Ÿåº¦åˆ†æçµæœ")
                                fig_sensitivity = whatif.plot_feature_sensitivity(sensitivity_df, selected_feature)
                                st.plotly_chart(fig_sensitivity, use_container_width=True)
                                
                                # ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«
                                st.subheader("ğŸ“‹ è©³ç´°ãƒ‡ãƒ¼ã‚¿")
                                st.dataframe(sensitivity_df, use_container_width=True)
                                
                                show_success_message("æ„Ÿåº¦åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                                
                            except Exception as e:
                                st.error(f"åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                else:
                    st.warning("æ•°å€¤å‹ã®ç‰¹å¾´é‡ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            
            else:  # ã‚·ãƒŠãƒªã‚ªæ¯”è¼ƒ
                st.subheader("ğŸ“ ãƒ™ãƒ¼ã‚¹æ¡ä»¶ã‚’å…¥åŠ›")
                input_data_scenario = create_prediction_form(feature_columns, df_original, "scenario")
                
                st.markdown("---")
                st.subheader("ğŸ“Š ã‚·ãƒŠãƒªã‚ªã‚’å®šç¾©")
                
                # ã‚·ãƒŠãƒªã‚ªæ•°ã‚’é¸æŠ
                n_scenarios = st.number_input("ã‚·ãƒŠãƒªã‚ªæ•°", min_value=1, max_value=5, value=2)
                
                scenarios = {}
                numeric_features = [col for col in feature_columns 
                                   if df_original[col].dtype in ['int64', 'float64', 'int32', 'float32']]
                
                for i in range(int(n_scenarios)):
                    with st.expander(f"ã‚·ãƒŠãƒªã‚ª {i+1}", expanded=True):
                        scenario_name = st.text_input(f"ã‚·ãƒŠãƒªã‚ªå", value=f"ã‚·ãƒŠãƒªã‚ª{i+1}", key=f"scenario_name_{i}")
                        
                        changes = {}
                        selected_features = st.multiselect(
                            "å¤‰æ›´ã™ã‚‹ç‰¹å¾´é‡",
                            numeric_features,
                            key=f"scenario_features_{i}"
                        )
                        
                        for feat in selected_features:
                            base_val = input_data_scenario.get(feat, df_original[feat].mean())
                            new_val = st.number_input(
                                f"{feat} ã®æ–°ã—ã„å€¤",
                                value=float(base_val),
                                key=f"scenario_{i}_{feat}"
                            )
                            changes[feat] = new_val
                        
                        if changes:
                            scenarios[scenario_name] = changes
                
                if st.button("ğŸ“Š ã‚·ãƒŠãƒªã‚ªæ¯”è¼ƒã‚’å®Ÿè¡Œ", key="run_scenario"):
                    if scenarios:
                        with st.spinner("åˆ†æä¸­..."):
                            try:
                                df_base = pd.DataFrame([input_data_scenario])
                                
                                preprocessor = st.session_state.get('preprocessor')
                                if preprocessor and not st.session_state.get('use_native_cat', False):
                                    df_base_processed = preprocessor.transform_new_data(df_base)
                                else:
                                    df_base_processed = df_base
                                
                                if not st.session_state.get('use_native_cat', False):
                                    df_base_processed = df_base_processed.select_dtypes(include=[np.number])
                                
                                # What-ifåˆ†æå™¨
                                X_original = df_original.drop(columns=[target_column], errors='ignore')
                                whatif = WhatIfAnalyzer(trainer.model, feature_columns, X_original)
                                
                                # ã‚·ãƒŠãƒªã‚ªæ¯”è¼ƒå®Ÿè¡Œ
                                scenario_df = whatif.compare_scenarios(df_base_processed, scenarios)
                                
                                # çµæœè¡¨ç¤º
                                st.subheader("ğŸ“Š ã‚·ãƒŠãƒªã‚ªæ¯”è¼ƒçµæœ")
                                fig_scenario = whatif.plot_scenario_comparison(scenario_df)
                                st.plotly_chart(fig_scenario, use_container_width=True)
                                
                                # ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«
                                st.subheader("ğŸ“‹ è©³ç´°ãƒ‡ãƒ¼ã‚¿")
                                st.dataframe(scenario_df, use_container_width=True)
                                
                                show_success_message("ã‚·ãƒŠãƒªã‚ªæ¯”è¼ƒãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                                
                            except Exception as e:
                                st.error(f"åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                    else:
                        st.warning("å°‘ãªãã¨ã‚‚1ã¤ã®ã‚·ãƒŠãƒªã‚ªã‚’å®šç¾©ã—ã¦ãã ã•ã„ã€‚")


def train_model(model_type, use_tuning, n_trials, use_cv, cv_folds, test_size,
                use_xgb_stack=True, use_lgb_stack=True, use_cat_stack=True,
                include_stacking=False):
    """ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã‚’å®Ÿè¡Œ"""
    
    df_processed = st.session_state['df_processed']
    target_column = st.session_state['target_column']
    
    X = df_processed.drop(columns=[target_column])
    y = df_processed[target_column]
    
    use_native_cat = st.session_state.get('use_native_cat', False)
    if not use_native_cat:
        X = X.select_dtypes(include=[np.number])
    
    st.session_state['feature_columns'] = X.columns.tolist()
    
    cat_features = None
    if use_native_cat:
        cat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()
        if cat_cols:
            cat_features = [X.columns.get_loc(col) for col in cat_cols]
    
    if model_type == "å…¨ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ":
        with st.spinner("å…¨ãƒ¢ãƒ‡ãƒ«ã‚’æ¯”è¼ƒä¸­..."):
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            from sklearn.model_selection import train_test_split
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=test_size, random_state=42
            )
            
            status_text.text("ãƒ¢ãƒ‡ãƒ«ã‚’æ¯”è¼ƒä¸­...")
            progress_bar.progress(30)
            
            X_train_num = X_train.select_dtypes(include=[np.number])
            X_test_num = X_test.select_dtypes(include=[np.number])
            
            comparison_results = compare_models(
                X_train_num, X_test_num, y_train, y_test,
                include_stacking=include_stacking
            )
            
            progress_bar.progress(100)
            status_text.text("å®Œäº†ï¼")
            
            best_model_type = get_best_model(comparison_results)
            
            trainer = ModelTrainer()
            trainer.model = comparison_results[best_model_type]['model']
            trainer.model_type = best_model_type
            trainer.feature_importance = comparison_results[best_model_type]['feature_importance']
            trainer.y_pred = comparison_results[best_model_type]['predictions']
            trainer.y_test = y_test
            
            st.session_state['trainer'] = trainer
            st.session_state['metrics'] = comparison_results[best_model_type]['metrics']
            st.session_state['is_trained'] = True
            st.session_state['comparison_results'] = comparison_results
            
            show_success_message(f"æ¯”è¼ƒå®Œäº†ï¼æœ€è‰¯ãƒ¢ãƒ‡ãƒ«: {best_model_type.upper()}")
            st.dataframe(comparison_results['comparison_df'], use_container_width=True)
    
    elif model_type == "ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚° (ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«)":
        with st.spinner("ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ä¸­..."):
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            from sklearn.model_selection import train_test_split
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=test_size, random_state=42
            )
            
            X_train_num = X_train.select_dtypes(include=[np.number])
            X_test_num = X_test.select_dtypes(include=[np.number])
            
            status_text.text("ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ä¸­...")
            progress_bar.progress(30)
            
            stacking_trainer = StackingTrainer()
            stacking_trainer.train(
                X_train_num, y_train,
                use_xgboost=use_xgb_stack,
                use_lightgbm=use_lgb_stack,
                use_catboost=use_cat_stack,
                cv_folds=cv_folds
            )
            
            progress_bar.progress(80)
            status_text.text("è©•ä¾¡ä¸­...")
            
            metrics = stacking_trainer.evaluate(X_test_num, y_test)
            
            progress_bar.progress(100)
            status_text.text("å®Œäº†ï¼")
            
            st.session_state['trainer'] = stacking_trainer
            st.session_state['metrics'] = metrics
            st.session_state['is_trained'] = True
            st.session_state['model_type'] = 'stacking'
            
            show_success_message("ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("RÂ² Score", f"{metrics['r2']:.4f}")
            with col2:
                st.metric("RMSE", f"{metrics['rmse']:.4f}")
            with col3:
                st.metric("MAE", f"{metrics['mae']:.4f}")
            with col4:
                st.metric("MAPE", f"{metrics['mape']:.2f}%")
            
    else:
        trainer = ModelTrainer()
        
        model_map = {
            'XGBoost': 'xgboost',
            'LightGBM': 'lightgbm',
            'CatBoost': 'catboost'
        }
        selected_model = model_map[model_type]
        
        X_train, X_test, y_train, y_test = trainer.prepare_data(X, y, test_size=test_size)
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        if use_tuning:
            status_text.text(f"ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­... ({n_trials}è©¦è¡Œ)")
            
            X_train_num = X_train.select_dtypes(include=[np.number])
            
            def update_progress(progress):
                progress_bar.progress(int(progress * 50))
            
            tuning_results = trainer.tune_hyperparameters(
                X_train_num, y_train,
                model_type=selected_model,
                n_trials=n_trials,
                cv_folds=cv_folds,
                progress_callback=update_progress
            )
            
            st.write("æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:", tuning_results['best_params'])
            progress_bar.progress(50)
        else:
            progress_bar.progress(25)
        
        status_text.text("ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ä¸­...")
        
        if selected_model != 'catboost' or not use_native_cat:
            X_train_fit = X_train.select_dtypes(include=[np.number])
            X_test_fit = X_test.select_dtypes(include=[np.number])
            trainer.train(X_train_fit, y_train, model_type=selected_model, use_default_params=not use_tuning)
        else:
            X_train_fit = X_train
            X_test_fit = X_test
            trainer.train(X_train_fit, y_train, model_type=selected_model, 
                         use_default_params=not use_tuning, cat_features=cat_features)
        
        progress_bar.progress(70)
        
        if use_cv:
            status_text.text("äº¤å·®æ¤œè¨¼ã‚’å®Ÿè¡Œä¸­...")
            X_cv = X.select_dtypes(include=[np.number]) if selected_model != 'catboost' or not use_native_cat else X
            cv_scores = trainer.cross_validate(X_cv, y, cv_folds=cv_folds)
            st.write(f"CV RÂ² Score: {cv_scores['r2_mean']:.4f} (Â±{cv_scores['r2_std']:.4f})")
        
        progress_bar.progress(90)
        
        status_text.text("ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ä¸­...")
        metrics = trainer.evaluate(X_test_fit, y_test)
        trainer.y_test = y_test
        
        progress_bar.progress(100)
        status_text.text("å®Œäº†ï¼")
        
        st.session_state['trainer'] = trainer
        st.session_state['metrics'] = metrics
        st.session_state['is_trained'] = True
        st.session_state['model_type'] = selected_model
        
        show_success_message(f"{model_type} ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("RÂ² Score", f"{metrics['r2']:.4f}")
        with col2:
            st.metric("RMSE", f"{metrics['rmse']:.4f}")
        with col3:
            st.metric("MAE", f"{metrics['mae']:.4f}")
        with col4:
            st.metric("MAPE", f"{metrics['mape']:.2f}%")


def save_model():
    """ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜"""
    trainer = st.session_state['trainer']
    
    from datetime import datetime
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    model_type = st.session_state.get('model_type', 'model')
    filename = f"model_{model_type}_{timestamp}.joblib"
    filepath = os.path.join('models', filename)
    
    try:
        trainer.save_model(filepath)
        show_success_message(f"ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {filename}")
    except Exception as e:
        st.error(f"ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")


def load_saved_model(uploaded_model):
    """ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
    try:
        import joblib
        import tempfile
        
        with tempfile.NamedTemporaryFile(delete=False, suffix='.joblib') as tmp:
            tmp.write(uploaded_model.getvalue())
            tmp_path = tmp.name
        
        trainer = ModelTrainer()
        model_data = trainer.load_model(tmp_path)
        
        st.session_state['trainer'] = trainer
        st.session_state['metrics'] = model_data['metrics']
        st.session_state['is_trained'] = True
        st.session_state['model_type'] = model_data['model_type']
        
        show_success_message(f"ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {model_data['model_type']}")
        
        os.unlink(tmp_path)
        
    except Exception as e:
        st.error(f"èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")


if __name__ == "__main__":
    main()
