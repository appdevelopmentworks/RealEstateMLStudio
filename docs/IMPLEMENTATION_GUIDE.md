# å®Ÿè£…ã‚¬ã‚¤ãƒ‰ï¼ˆãƒã‚¤ãƒ–ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ç”¨ï¼‰

**ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå**: RealEstateMLStudio  
**ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: 2.3  
**æœ€çµ‚æ›´æ–°**: 2026-01-01

---

ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ã€AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆï¼ˆClaudeç­‰ï¼‰ãŒã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’ã‚¼ãƒ­ã‹ã‚‰å†å®Ÿè£…ã™ã‚‹ãŸã‚ã®è©³ç´°ã‚¬ã‚¤ãƒ‰ã§ã™ã€‚

---

## 1. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦

### 1.1 ä¸€è¨€ã§èª¬æ˜

ã€Œä¸å‹•ç”£ä¾¡æ ¼ã‚’æ©Ÿæ¢°å­¦ç¿’ã§äºˆæ¸¬ã—ã€SHAPåˆ†æã§èª¬æ˜å¯èƒ½ã«ã™ã‚‹Streamlitã‚¢ãƒ—ãƒªã€

### 1.2 ã‚³ã‚¢æ©Ÿèƒ½

1. **ãƒ‡ãƒ¼ã‚¿å‡¦ç†**: CSVèª­ã¿è¾¼ã¿ â†’ å‰å‡¦ç† â†’ ç‰¹å¾´é‡/ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ†é›¢
2. **ãƒ¢ãƒ‡ãƒ«å­¦ç¿’**: XGBoost/LightGBM/CatBoost/ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°
3. **è©•ä¾¡å¯è¦–åŒ–**: RÂ², RMSEç­‰ã®æŒ‡æ¨™ã‚’Plotlyãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã§è¡¨ç¤º
4. **äºˆæ¸¬å®Ÿè¡Œ**: æ–°ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹ä¾¡æ ¼äºˆæ¸¬
5. **èª¬æ˜å¯èƒ½AI**: SHAPåˆ†æã«ã‚ˆã‚‹äºˆæ¸¬æ ¹æ‹ ã®å¯è¦–åŒ–
6. **ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£**: é¡ä¼¼ç‰©ä»¶æ¤œç´¢ã€ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯ç­‰

---

## 2. å®Ÿè£…æ‰‹é †

### Phase 1: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ä½œæˆ

```bash
mkdir RealEstateMLStudio
cd RealEstateMLStudio
mkdir src data models reports images docs
touch app.py requirements.txt README.md
touch src/__init__.py src/preprocessor.py src/trainer.py src/visualizer.py src/analysis.py src/utils.py
```

### Phase 2: ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ï¼ˆrequirements.txtï¼‰

```
streamlit>=1.28.0
pandas>=2.0.0
numpy>=1.24.0
scikit-learn>=1.3.0
xgboost>=2.0.0
lightgbm>=4.0.0
catboost>=1.2.0
optuna>=3.4.0
shap>=0.43.0
plotly>=5.18.0
seaborn>=0.13.0
matplotlib>=3.8.0
japanize-matplotlib>=1.1.3
Pillow>=10.0.0
joblib>=1.3.0
openpyxl>=3.1.0
fpdf2>=2.7.0
kaleido>=0.2.1
```

### Phase 3: å„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å®Ÿè£…

ä»¥ä¸‹ã®é †åºã§å®Ÿè£…ã‚’é€²ã‚ã‚‹ï¼š

1. `src/utils.py` - å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
2. `src/preprocessor.py` - ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†
3. `src/trainer.py` - ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
4. `src/visualizer.py` - å¯è¦–åŒ–
5. `src/analysis.py` - é«˜åº¦åˆ†æ
6. `app.py` - ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒª

---

## 3. ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆ¥å®Ÿè£…ã‚¬ã‚¤ãƒ‰

### 3.1 utils.py

**ç›®çš„**: å…±é€šé–¢æ•°ã€CSSã€ãƒ˜ãƒ«ãƒ‘ãƒ¼

```python
# å¿…é ˆã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import pandas as pd
import numpy as np
import streamlit as st
from datetime import datetime
import os

# å®Ÿè£…ã™ã¹ãé–¢æ•°
def load_css():
    """ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³èƒŒæ™¯ã€ã‚«ãƒ¼ãƒ‰ã€ãƒœã‚¿ãƒ³ã‚¹ã‚¿ã‚¤ãƒ«ã®CSS"""
    css = """
    <style>
        .main-header { 
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            padding: 2rem; border-radius: 15px; color: white; text-align: center;
        }
        .metric-card { ... }
        .success-box { background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%); ... }
        .warning-box { background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%); ... }
    </style>
    """
    st.markdown(css, unsafe_allow_html=True)

def init_session_state():
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³å¤‰æ•°ã®åˆæœŸåŒ–"""
    defaults = {
        'df': None, 'df_processed': None, 'preprocessor': None,
        'trainer': None, 'model': None, 'is_trained': False, ...
    }
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

def show_success_message(message: str):
    st.markdown(f'<div class="success-box">âœ… {message}</div>', unsafe_allow_html=True)

def show_warning_message(message: str):
    st.markdown(f'<div class="warning-box">âš ï¸ {message}</div>', unsafe_allow_html=True)

def display_dataframe_info(df):
    """4åˆ—ã§rows, columns, missing, memoryã‚’è¡¨ç¤º"""
    col1, col2, col3, col4 = st.columns(4)
    with col1: st.metric("è¡Œæ•°", f"{len(df):,}")
    ...
```

### 3.2 preprocessor.py

**ç›®çš„**: ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

```python
# å¿…é ˆã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder
from sklearn.impute import SimpleImputer

class DataPreprocessor:
    def __init__(self):
        self.label_encoders = {}
        self.scaler = None
        self.imputers = {}
        self.numeric_columns = None
        self.categorical_columns = None
    
    def auto_preprocess(self, df, target_column=None, handle_missing=True, 
                        encode_cat=True, handle_outliers_flag=False, scale=False):
        """
        è‡ªå‹•å‰å‡¦ç†ã®ä¸»è¦ãƒ­ã‚¸ãƒƒã‚¯:
        1. ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ—ã‚’ä¸€æ™‚åˆ†é›¢
        2. æ•°å€¤/ã‚«ãƒ†ã‚´ãƒªåˆ—ã‚’è‡ªå‹•è­˜åˆ¥
        3. æ¬ æå€¤å‡¦ç†ï¼ˆæ•°å€¤â†’ä¸­å¤®å€¤ã€ã‚«ãƒ†ã‚´ãƒªâ†’æœ€é »å€¤ï¼‰
        4. ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã‚’LabelEncoder
        5. ç•°å¸¸å€¤å‡¦ç†ï¼ˆIQRæ³•ã§clipï¼‰
        6. ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼ˆStandardScalerï¼‰
        7. ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ—ã‚’æˆ»ã™
        """
        df_processed = df.copy()
        
        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ†é›¢
        target = None
        if target_column and target_column in df_processed.columns:
            target = df_processed[target_column].copy()
            df_processed = df_processed.drop(columns=[target_column])
        
        # åˆ—ã‚¿ã‚¤ãƒ—è­˜åˆ¥
        self.numeric_columns = df_processed.select_dtypes(include=[np.number]).columns.tolist()
        self.categorical_columns = df_processed.select_dtypes(include=['object']).columns.tolist()
        
        # å„å‡¦ç†ã‚’å®Ÿè¡Œ...
        
        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¾©å…ƒ
        if target is not None:
            df_processed[target_column] = target.values
        
        return df_processed
    
    def transform_new_data(self, df):
        """å­¦ç¿’æ™‚ã¨åŒã˜å¤‰æ›ã‚’é©ç”¨ï¼ˆäºˆæ¸¬æ™‚ç”¨ï¼‰"""
        df_processed = df.copy()
        # imputers, label_encoders, scalerã‚’é †ã«é©ç”¨
        return df_processed
```

### 3.3 trainer.py

**ç›®çš„**: MLãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãƒ»è©•ä¾¡

```python
# å¿…é ˆã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, cross_val_score, KFold
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error
from sklearn.linear_model import ElasticNet
from sklearn.ensemble import StackingRegressor
from xgboost import XGBRegressor
from lightgbm import LGBMRegressor
from catboost import CatBoostRegressor
import optuna
import joblib

class ModelTrainer:
    def __init__(self):
        self.model = None
        self.model_type = None
        self.best_params = None
        self.feature_importance = None
        self.metrics = {}
        self.y_pred = None
        self.y_test = None
    
    def tune_hyperparameters(self, X, y, model_type='xgboost', n_trials=50, cv_folds=5):
        """
        Optunaã«ã‚ˆã‚‹ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°:
        1. TPESamplerã§studyä½œæˆ
        2. ç›®çš„é–¢æ•°ã§å„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’trial.suggest_*ã§æ¢ç´¢
        3. cross_val_scoreã§MSEã‚’è©•ä¾¡
        4. æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’self.best_paramsã«ä¿å­˜
        """
        sampler = optuna.samplers.TPESampler(seed=42)
        study = optuna.create_study(direction='minimize', sampler=sampler)
        
        def objective(trial):
            if model_type == 'xgboost':
                params = {
                    'n_estimators': trial.suggest_int('n_estimators', 100, 1000),
                    'max_depth': trial.suggest_int('max_depth', 3, 12),
                    'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),
                    ...
                }
                model = XGBRegressor(**params)
            ...
            scores = cross_val_score(model, X, y, cv=cv_folds, scoring='neg_mean_squared_error')
            return -scores.mean()
        
        study.optimize(objective, n_trials=n_trials)
        self.best_params = study.best_params
        return {'best_params': self.best_params, 'best_score': study.best_value}
    
    def train(self, X_train, y_train, model_type='xgboost', params=None):
        """
        ãƒ¢ãƒ‡ãƒ«å­¦ç¿’:
        1. model_typeã«å¿œã˜ã¦ãƒ¢ãƒ‡ãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ
        2. paramsæŒ‡å®šãªã‘ã‚Œã°best_paramsã¾ãŸã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆä½¿ç”¨
        3. fitå®Ÿè¡Œ
        4. feature_importanceã‚’ä¿å­˜
        """
        if model_type == 'xgboost':
            self.model = XGBRegressor(**params)
        elif model_type == 'lightgbm':
            self.model = LGBMRegressor(**params)
        elif model_type == 'catboost':
            self.model = CatBoostRegressor(**params, verbose=False)
        
        self.model.fit(X_train, y_train)
        self.feature_importance = pd.Series(
            self.model.feature_importances_, index=X_train.columns
        ).sort_values(ascending=False)
        return self.model
    
    def evaluate(self, X_test, y_test):
        """RMSE, MAE, RÂ², MAPEã‚’è¨ˆç®—"""
        self.y_pred = self.model.predict(X_test)
        self.y_test = y_test
        self.metrics = {
            'rmse': np.sqrt(mean_squared_error(y_test, self.y_pred)),
            'mae': mean_absolute_error(y_test, self.y_pred),
            'r2': r2_score(y_test, self.y_pred),
            'mape': mean_absolute_percentage_error(y_test, self.y_pred) * 100
        }
        return self.metrics

class StackingTrainer:
    """XGBoost + LightGBM + CatBoost ã‚’ElasticNetã§ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°"""
    def train(self, X_train, y_train, use_xgboost=True, use_lightgbm=True, use_catboost=True):
        estimators = []
        if use_xgboost:
            estimators.append(('xgboost', XGBRegressor(...)))
        if use_lightgbm:
            estimators.append(('lightgbm', LGBMRegressor(...)))
        if use_catboost:
            estimators.append(('catboost', CatBoostRegressor(...)))
        
        self.model = StackingRegressor(
            estimators=estimators,
            final_estimator=ElasticNet(alpha=0.1, l1_ratio=0.5),
            cv=5, n_jobs=-1
        )
        self.model.fit(X_train, y_train)
        return self.model

def compare_models(X_train, X_test, y_train, y_test, include_stacking=False):
    """3ãƒ¢ãƒ‡ãƒ«ï¼ˆ+ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°ï¼‰ã‚’æ¯”è¼ƒã—ã¦DataFrameè¿”å´"""
    results = {}
    # å„ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ãƒ»è©•ä¾¡
    # comparison_df = pd.DataFrame({...}, index=['RMSE', 'MAE', 'RÂ²', 'MAPE'])
    return results
```

### 3.4 visualizer.py

**ç›®çš„**: Plotlyã«ã‚ˆã‚‹ã‚°ãƒ©ãƒ•ç”Ÿæˆ

```python
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots

COLORS = {
    'primary': '#1f77b4',
    'secondary': '#ff7f0e',
    'success': '#2ca02c',
    ...
}

class Visualizer:
    def __init__(self):
        self.theme = 'plotly_white'
    
    def plot_actual_vs_predicted(self, y_true, y_pred, title="å®Ÿæ¸¬å€¤ vs äºˆæ¸¬å€¤"):
        """
        æ•£å¸ƒå›³:
        - æ®‹å·®ã®å¤§ãã•ã§ã‚«ãƒ©ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«
        - 45åº¦ç·šï¼ˆå®Œå…¨äºˆæ¸¬ç·šï¼‰
        - å›å¸°ç·š
        """
        fig = go.Figure()
        residuals = y_true - y_pred
        
        fig.add_trace(go.Scatter(
            x=y_true, y=y_pred, mode='markers',
            marker=dict(color=np.abs(residuals), colorscale='RdYlGn_r', showscale=True),
            hovertemplate="å®Ÿæ¸¬: %{x}<br>äºˆæ¸¬: %{y}"
        ))
        
        # 45åº¦ç·š
        fig.add_trace(go.Scatter(
            x=[y_true.min(), y_true.max()],
            y=[y_true.min(), y_true.max()],
            mode='lines', line=dict(color='red', dash='dash'),
            name='å®Œå…¨äºˆæ¸¬ç·š'
        ))
        
        fig.update_layout(template=self.theme, ...)
        return fig
    
    def plot_metrics_dashboard(self, metrics, cv_scores=None):
        """
        4ã¤ã®ã‚²ãƒ¼ã‚¸ãƒãƒ£ãƒ¼ãƒˆ:
        - RMSEï¼ˆä½ã„ã»ã©è‰¯ã„ï¼‰
        - RÂ²ï¼ˆ1ã«è¿‘ã„ã»ã©è‰¯ã„ã€è‰²ä»˜ãã‚¹ãƒ†ãƒƒãƒ—ï¼‰
        - MAE
        - MAPEï¼ˆ%è¡¨ç¤ºï¼‰
        """
        fig = make_subplots(rows=2, cols=2, specs=[[{"type": "indicator"}]*2]*2)
        
        # RMSE
        fig.add_trace(go.Indicator(
            mode="gauge+number",
            value=metrics['rmse'],
            title={"text": "RMSE<br><span style='font-size:11px;color:gray'>ä½ã„ã»ã©è‰¯ã„</span>"},
            gauge=dict(axis=dict(range=[0, metrics['rmse']*2]), ...)
        ), row=1, col=1)
        
        # RÂ² (ã‚¹ãƒ†ãƒƒãƒ—ã‚«ãƒ©ãƒ¼)
        fig.add_trace(go.Indicator(
            mode="gauge+number",
            value=metrics['r2'],
            gauge=dict(
                axis=dict(range=[0, 1]),
                steps=[
                    dict(range=[0, 0.5], color="#ffebee"),
                    dict(range=[0.5, 0.7], color="#fff3e0"),
                    dict(range=[0.7, 0.9], color="#e8f5e9"),
                    dict(range=[0.9, 1], color="#c8e6c9"),
                ]
            )
        ), row=1, col=2)
        
        ...
        return fig
    
    def plot_feature_importance(self, feature_importance, top_n=20):
        """æ°´å¹³ãƒãƒ¼ãƒãƒ£ãƒ¼ãƒˆã€Viridisã‚«ãƒ©ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«"""
        fi = feature_importance.head(top_n).sort_values(ascending=True)
        fig = go.Figure(go.Bar(
            x=fi.values, y=fi.index, orientation='h',
            marker=dict(color=px.colors.sample_colorscale('Viridis', len(fi)))
        ))
        return fig
```

### 3.5 analysis.py

**ç›®çš„**: SHAPåˆ†æã€ä¿¡é ¼åŒºé–“ã€What-ifåˆ†æã€PDFç”Ÿæˆã€ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£

```python
import shap
import numpy as np
import pandas as pd
from scipy import stats
from fpdf import FPDF

class SHAPAnalyzer:
    def __init__(self, model, X_train):
        self.model = model
        self.X_train = X_train
        self.explainer = None
        self.shap_values = None
    
    def calculate_shap_values(self, X=None, max_samples=500):
        """
        ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã‚’åˆ¤å®šã—ã¦é©åˆ‡ãªExplainerã‚’ä½¿ç”¨:
        - XGBoost/LightGBM/CatBoost â†’ TreeExplainer
        - Stacking â†’ KernelExplainer
        - ãã®ä»– â†’ Permutation Explainerï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
        """
        if X is None:
            X = self.X_train
        if len(X) > max_samples:
            X = X.sample(n=max_samples, random_state=42)
        
        model_type = type(self.model).__name__
        
        try:
            if 'XGB' in model_type or 'LGBM' in model_type or 'CatBoost' in model_type:
                self.explainer = shap.TreeExplainer(self.model)
                self.shap_values = self.explainer.shap_values(X)
            else:
                # KernelExplainerã¾ãŸã¯PermutationExplainerã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                ...
        except Exception:
            # æœ€çµ‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            ...
        
        self.X_sample = X
        return self.shap_values
    
    def explain_prediction(self, X_single):
        """
        å˜ä¸€äºˆæ¸¬ã®èª¬æ˜:
        - base_valueï¼ˆæœŸå¾…å€¤ï¼‰
        - å„ç‰¹å¾´é‡ã®SHAPå€¤
        - è²¢çŒ®åº¦ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆæ­£è² ã€å½±éŸ¿ã®æ–¹å‘ï¼‰
        """
        shap_values_single = self.explainer.shap_values(X_single)[0]
        base_value = self.explainer.expected_value
        
        contributions = pd.DataFrame({
            'ç‰¹å¾´é‡': X_single.columns,
            'å€¤': X_single.values[0],
            'SHAPå€¤': shap_values_single,
            'å½±éŸ¿': ['â†‘ ä¾¡æ ¼ä¸Šæ˜‡' if v > 0 else 'â†“ ä¾¡æ ¼ä¸‹è½' for v in shap_values_single]
        }).sort_values('SHAPå€¤', key=abs, ascending=False)
        
        return {
            'base_value': base_value,
            'shap_values': shap_values_single,
            'contributions': contributions,
            'prediction': base_value + shap_values_single.sum()
        }

class PredictionInterval:
    def __init__(self, model, X_train, y_train):
        self.model = model
        self.X_train = X_train
        self.y_train = y_train
        self.residual_std = None
    
    def fit(self):
        """æ®‹å·®ã®æ¨™æº–åå·®ã‚’è¨ˆç®—"""
        y_pred = self.model.predict(self.X_train)
        residuals = self.y_train.values - y_pred
        self.residual_std = np.std(residuals)
        return self
    
    def predict_single_with_interval(self, X_single, confidence_levels=[0.5, 0.8, 0.95]):
        """
        ä¿¡é ¼åŒºé–“è¨ˆç®—:
        - å„ä¿¡é ¼æ°´æº–ã«å¯¾å¿œã™ã‚‹zå€¤ã‚’å–å¾—
        - margin = z * residual_std
        - lower/upper = prediction Â± margin
        """
        prediction = self.model.predict(X_single)[0]
        intervals = {}
        for conf in confidence_levels:
            z = stats.norm.ppf(1 - (1 - conf) / 2)
            margin = z * self.residual_std
            intervals[f'{int(conf*100)}%'] = {
                'lower': prediction - margin,
                'upper': prediction + margin,
                'margin': margin
            }
        return {'prediction': prediction, 'intervals': intervals}

class WhatIfAnalyzer:
    def analyze_feature_impact(self, X_base, feature, n_points=20):
        """
        æ„Ÿåº¦åˆ†æ:
        1. ç‰¹å¾´é‡ã®ç¯„å›²ã‚’å–å¾—
        2. n_pointså€‹ã®å€¤ã‚’ç”Ÿæˆ
        3. å„å€¤ã§X_baseã‚’å¤‰æ›´ã—ã¦äºˆæ¸¬
        4. å¤‰åŒ–é‡ãƒ»å¤‰åŒ–ç‡ã‚’è¨ˆç®—
        """
        values = np.linspace(self.X_original[feature].min(), 
                            self.X_original[feature].max(), n_points)
        base_pred = self.model.predict(X_base)[0]
        
        results = []
        for val in values:
            X_modified = X_base.copy()
            X_modified[feature] = val
            new_pred = self.model.predict(X_modified)[0]
            results.append({
                feature: val,
                'äºˆæ¸¬ä¾¡æ ¼': new_pred,
                'å¤‰åŒ–é‡': new_pred - base_pred,
                'å¤‰åŒ–ç‡(%)': (new_pred - base_pred) / base_pred * 100
            })
        return pd.DataFrame(results)

class PDFReportGenerator:
    def generate_report(self, prediction_result, shap_explanation=None, ...):
        """
        fpdf2ã§PDFç”Ÿæˆ:
        1. ãƒ˜ãƒƒãƒ€ãƒ¼ï¼ˆã‚¿ã‚¤ãƒˆãƒ«ã€æ—¥æ™‚ï¼‰
        2. äºˆæ¸¬ã‚µãƒãƒªãƒ¼
        3. å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«
        4. SHAPåˆ†æçµæœï¼ˆæ­£è² ã®è¦å› ï¼‰
        5. ãƒ¢ãƒ‡ãƒ«æ€§èƒ½
        6. å…è²¬äº‹é …
        """
        class PDF(FPDF):
            def header(self): ...
            def footer(self): ...
        
        pdf = PDF()
        pdf.add_page()
        # å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ ...
        return bytes(pdf.output())

class SimilarPropertyFinder:
    """
    é¡ä¼¼ç‰©ä»¶æ¤œç´¢:
    - StandardScalerã§æ­£è¦åŒ–
    - euclidean_distances ã¾ãŸã¯ cosine_similarity
    - ä¸Šä½Nä»¶ã‚’è¿”å´
    """

class DataQualityChecker:
    """
    ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯:
    - é‡è¤‡è¡Œã€æ¬ æå€¤ã€ç•°å¸¸å€¤ï¼ˆIQRï¼‰
    - å‹ã®å•é¡Œã€é«˜ç›¸é–¢ãƒšã‚¢
    - å“è³ªã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆ100 - issues * 2ï¼‰
    """

class FeatureEngineer:
    """
    ç‰¹å¾´é‡è‡ªå‹•ç”Ÿæˆ:
    - äº¤äº’ä½œç”¨: col1 * col2
    - å¤šé …å¼: col^2, sqrt(col)
    - æ¯”ç‡: col1 / col2
    - ãƒ“ãƒ‹ãƒ³ã‚°: pd.qcut
    """

class PredictionHistory:
    """
    äºˆæ¸¬å±¥æ­´ç®¡ç†:
    - ãƒªã‚¹ãƒˆã§å±¥æ­´ä¿æŒ
    - DataFrameå¤‰æ›
    - CSV/JSONã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
    - çµ±è¨ˆè¨ˆç®—
    """
```

### 3.6 app.py

**ç›®çš„**: ãƒ¡ã‚¤ãƒ³Streamlitã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³

```python
import streamlit as st
import pandas as pd
import numpy as np
import os
import sys
from datetime import datetime

sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from src.preprocessor import DataPreprocessor
from src.trainer import ModelTrainer, StackingTrainer, compare_models
from src.visualizer import Visualizer
from src.analysis import SHAPAnalyzer, PredictionInterval, WhatIfAnalyzer, PDFReportGenerator, ...
from src.utils import load_css, init_session_state, show_success_message, ...

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="RealEstateMLStudio",
    page_icon="ğŸ ",
    layout="wide",
    initial_sidebar_state="expanded"
)

load_css()
init_session_state()
viz = Visualizer()

def main():
    # ãƒ˜ãƒƒãƒ€ãƒ¼ç”»åƒ or ãƒ†ã‚­ã‚¹ãƒˆãƒ˜ãƒƒãƒ€ãƒ¼
    if os.path.exists("images/Appbanner.png"):
        st.image("images/Appbanner.png", use_container_width=True)
    else:
        create_header("RealEstateMLStudio", "...")
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    with st.sidebar:
        st.title("è¨­å®šãƒ‘ãƒãƒ«")
        model_type = st.selectbox("ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ é¸æŠ", 
            ["XGBoost", "LightGBM", "CatBoost", "ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°", "å…¨ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ"])
        use_tuning = st.checkbox("ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°")
        if use_tuning:
            n_trials = st.slider("è©¦è¡Œå›æ•°", 10, 200, 50)
        ...
    
    # 7ã‚¿ãƒ–æ§‹æˆ
    tabs = st.tabs([
        "ğŸ“¤ ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", "ğŸ” EDA", "ğŸ¯ ãƒ¢ãƒ‡ãƒ«å­¦ç¿’",
        "ğŸ“Š è©•ä¾¡çµæœ", "ğŸ”® äºˆæ¸¬å®Ÿè¡Œ", "ğŸ”¬ è©³ç´°åˆ†æ", "ğŸ› ï¸ ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£"
    ])
    
    with tabs[0]:
        render_data_upload_tab()
    with tabs[1]:
        render_eda_tab()
    # ...

def render_data_upload_tab():
    st.header("Step 1: ãƒ‡ãƒ¼ã‚¿ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    
    uploaded_file = st.file_uploader("å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=['csv'])
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ãƒœã‚¿ãƒ³
    if st.button("ã‚«ãƒªãƒ•ã‚©ãƒ«ãƒ‹ã‚¢ä½å®…ãƒ‡ãƒ¼ã‚¿"):
        df = load_sample_data("california")
        st.session_state['df'] = df
        st.rerun()
    
    if st.session_state.get('df') is not None:
        df = st.session_state['df']
        display_dataframe_info(df)
        st.dataframe(df.head(20))

def render_training_tab(model_type, use_tuning, ...):
    st.header("Step 3: ãƒ¢ãƒ‡ãƒ«å­¦ç¿’")
    
    df = st.session_state.get('df')
    target_column = st.selectbox("ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ—", df.columns.tolist())
    
    if st.button("å‰å‡¦ç†ã‚’å®Ÿè¡Œ"):
        preprocessor = DataPreprocessor()
        df_processed = preprocessor.auto_preprocess(df, target_column, ...)
        st.session_state['df_processed'] = df_processed
        st.session_state['preprocessor'] = preprocessor
    
    if st.button("å­¦ç¿’é–‹å§‹"):
        train_model(model_type, use_tuning, ...)

def train_model(model_type, use_tuning, ...):
    df_processed = st.session_state['df_processed']
    target_column = st.session_state['target_column']
    
    X = df_processed.drop(columns=[target_column])
    y = df_processed[target_column]
    X = X.select_dtypes(include=[np.number])
    
    st.session_state['feature_columns'] = X.columns.tolist()
    
    trainer = ModelTrainer()
    X_train, X_test, y_train, y_test = trainer.prepare_data(X, y)
    
    if use_tuning:
        trainer.tune_hyperparameters(X_train, y_train, model_type, n_trials)
    
    trainer.train(X_train, y_train, model_type)
    metrics = trainer.evaluate(X_test, y_test)
    
    st.session_state['trainer'] = trainer
    st.session_state['metrics'] = metrics
    st.session_state['is_trained'] = True

def render_advanced_analysis_tab():
    """SHAP, ä¿¡é ¼åŒºé–“, PDF, What-ifã®4ã‚µãƒ–ã‚¿ãƒ–"""
    tabs = st.tabs(["SHAPåˆ†æ", "äºˆæ¸¬ä¿¡é ¼åŒºé–“", "PDFãƒ¬ãƒãƒ¼ãƒˆ", "What-ifåˆ†æ"])
    
    with tabs[0]:  # SHAP
        if st.button("SHAPåˆ†æã‚’å®Ÿè¡Œ"):
            shap_analyzer = SHAPAnalyzer(trainer.model, X_train)
            shap_analyzer.calculate_shap_values()
            fig = shap_analyzer.plot_summary()
            st.plotly_chart(fig)
    
    with tabs[1]:  # ä¿¡é ¼åŒºé–“
        # å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
        # predict_single_with_interval
        # plot_prediction_interval
    
    # ...

def render_utility_tab():
    """é¡ä¼¼ç‰©ä»¶, å“è³ªãƒã‚§ãƒƒã‚¯, ç‰¹å¾´é‡ç”Ÿæˆ, å±¥æ­´ã®4ã‚µãƒ–ã‚¿ãƒ–"""
    tabs = st.tabs(["é¡ä¼¼ç‰©ä»¶æ¤œç´¢", "ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯", "ç‰¹å¾´é‡è‡ªå‹•ç”Ÿæˆ", "äºˆæ¸¬å±¥æ­´ç®¡ç†"])
    # å„ã‚¿ãƒ–ã®å®Ÿè£…

if __name__ == "__main__":
    main()
```

---

## 4. é‡è¦ãªå®Ÿè£…ãƒ‘ã‚¿ãƒ¼ãƒ³

### 4.1 ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®æ´»ç”¨

```python
# åˆæœŸåŒ–
if 'key' not in st.session_state:
    st.session_state['key'] = default_value

# ä¿å­˜
st.session_state['trainer'] = trainer

# å–å¾—
trainer = st.session_state.get('trainer')

# å­˜åœ¨ãƒã‚§ãƒƒã‚¯
if st.session_state.get('is_trained', False):
    ...
```

### 4.2 ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

```python
try:
    result = some_operation()
except Exception as e:
    st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
```

### 4.3 ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹è¡¨ç¤º

```python
progress_bar = st.progress(0)
status_text = st.empty()

for i in range(100):
    progress_bar.progress(i)
    status_text.text(f"å‡¦ç†ä¸­... {i}%")

progress_bar.progress(100)
status_text.text("å®Œäº†ï¼")
```

### 4.4 å‹•çš„ãƒ•ã‚©ãƒ¼ãƒ ç”Ÿæˆ

```python
def create_prediction_form(feature_columns, df_original, key_prefix):
    input_data = {}
    col1, col2 = st.columns(2)
    
    for i, col in enumerate(feature_columns):
        if df_original[col].dtype == 'object':
            # ã‚«ãƒ†ã‚´ãƒª â†’ selectbox
            with col1 if i % 2 == 0 else col2:
                input_data[col] = st.selectbox(col, df_original[col].unique())
        else:
            # æ•°å€¤ â†’ number_input
            with col1 if i % 2 == 0 else col2:
                input_data[col] = st.number_input(col, value=df_original[col].mean())
    
    return input_data
```

---

## 5. ãƒ†ã‚¹ãƒˆãƒ»ãƒ‡ãƒãƒƒã‚°

### 5.1 å‹•ä½œç¢ºèªæ‰‹é †

```bash
# èµ·å‹•
streamlit run app.py

# ãƒ–ãƒ©ã‚¦ã‚¶ã§ç¢ºèª
# 1. ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
# 2. EDAã‚¿ãƒ–ã§çµ±è¨ˆç¢ºèª
# 3. XGBoostã§ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
# 4. è©•ä¾¡çµæœç¢ºèª
# 5. æ‰‹å…¥åŠ›ã§äºˆæ¸¬
# 6. SHAPåˆ†æå®Ÿè¡Œ
```

### 5.2 ã‚ˆãã‚ã‚‹ã‚¨ãƒ©ãƒ¼ã¨å¯¾å‡¦

| ã‚¨ãƒ©ãƒ¼ | åŸå›  | å¯¾å‡¦ |
|--------|------|------|
| KeyError: 'df' | ãƒ‡ãƒ¼ã‚¿æœªèª­ã¿è¾¼ã¿ | ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ãƒã‚§ãƒƒã‚¯è¿½åŠ  |
| SHAPè¨ˆç®—å¤±æ•— | ãƒ¢ãƒ‡ãƒ«éå¯¾å¿œ | ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯Explainerä½¿ç”¨ |
| äºˆæ¸¬æ™‚ã‚¨ãƒ©ãƒ¼ | åˆ—ä¸ä¸€è‡´ | transform_new_dataä½¿ç”¨ |

---

## 6. æ‹¡å¼µã®ãƒ’ãƒ³ãƒˆ

### 6.1 æ–°ãƒ¢ãƒ‡ãƒ«è¿½åŠ 

1. `trainer.py`ã®`_objective_xxx`é–¢æ•°ã‚’è¿½åŠ 
2. `train`ãƒ¡ã‚½ãƒƒãƒ‰ã«åˆ†å²è¿½åŠ 
3. ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®é¸æŠè‚¢ã«è¿½åŠ 

### 6.2 æ–°åˆ†ææ©Ÿèƒ½è¿½åŠ 

1. `analysis.py`ã«æ–°ã‚¯ãƒ©ã‚¹ä½œæˆ
2. `app.py`ã®è©³ç´°åˆ†æã‚¿ãƒ–ã«ã‚µãƒ–ã‚¿ãƒ–è¿½åŠ 
3. ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«çµæœã‚’ä¿å­˜

### 6.3 UIæ”¹å–„

1. `utils.py`ã®CSSã‚’ç·¨é›†
2. ã‚«ãƒ©ãƒ¼ãƒ‘ãƒ¬ãƒƒãƒˆã‚’`visualizer.py`ã§èª¿æ•´
3. ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚’`st.columns`ã§èª¿æ•´
